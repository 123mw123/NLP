{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "questions_pairing",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyDHXG9OvMS-",
        "colab_type": "code",
        "outputId": "489a819d-088b-48c2-f020-af104c230523",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCDQIMpavfE5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "0c480485-83ce-4a07-b76c-34ed7f90c514"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Input, Dropout, LSTM, Activation,Lambda\n",
        "from keras.layers import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.initializers import glorot_uniform\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import model_from_json\n",
        "from keras import optimizers\n",
        "from keras.optimizers import Adadelta\n",
        "import keras.backend as K\n",
        "import string\n",
        "import csv\n",
        "np.random.seed(1)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obLCpjybBWmn",
        "colab_type": "text"
      },
      "source": [
        "# Loading & Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9JscRJk62RB",
        "colab_type": "code",
        "outputId": "aabd4acd-8830-4f9a-ab74-0d4805c72067",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data = pd.read_csv('/content/drive/My Drive/txt_datsets/quora/train.csv')\n",
        "print(data.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(363861, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKjAF6Lu7G-E",
        "colab_type": "code",
        "outputId": "d7f45f34-0b24-45fc-d8c9-63e0941f76b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sub_data = data[['question1','question2','is_duplicate']] \n",
        "print(sub_data.shape)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(363861, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1MyBH2d7VhR",
        "colab_type": "code",
        "outputId": "9eab27d6-371e-4a17-8297-9d6b708ac2e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "sub_data.dropna( inplace=True)\n",
        "print(sub_data.shape)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(363858, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tzvHXUj7em4",
        "colab_type": "code",
        "outputId": "25637799-2718-4655-aaaa-bf7c36eee085",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "sub_data.duplicated(subset={'question1','question2','is_duplicate'},).value_counts()\n",
        "sub_data.drop_duplicates(subset={'question1','question2','is_duplicate'},keep=\"first\",inplace=True)\n",
        "print(sub_data.shape)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(363858, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05v6GEKb7oyQ",
        "colab_type": "code",
        "outputId": "d53b3269-729a-413c-deca-4802d033a83c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "print(sub_data.head())"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                           question1  ... is_duplicate\n",
            "0  What is the step by step guide to invest in sh...  ...            0\n",
            "1  What is the story of Kohinoor (Koh-i-Noor) Dia...  ...            0\n",
            "2  How can I increase the speed of my internet co...  ...            0\n",
            "3  Why am I mentally very lonely? How can I solve...  ...            0\n",
            "4  Which one dissolve in water quikly sugar, salt...  ...            0\n",
            "\n",
            "[5 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddGbtA-ngoMP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2ac26b9a-30c5-48ed-a44a-17720c6501f1"
      },
      "source": [
        "pos = sub_data[sub_data[\"is_duplicate\"]>=0.5]\n",
        "print(pos.shape)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(135175, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6WaTtDtgvQP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "963cd46a-54a3-4cf3-afb0-5774a25320d2"
      },
      "source": [
        "neg = sub_data[sub_data[\"is_duplicate\"]<0.5]\n",
        "print(neg.shape)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(228683, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZndRoU8-gwVh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "19ec0081-918c-4dad-9035-9739435c56b2"
      },
      "source": [
        "neg = neg.sample(n=pos.shape[0],replace=True)\n",
        "print(neg.shape)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(135175, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxtWuq6lg0eB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "313850b7-9bc6-40f2-f930-6f2aeae0d381"
      },
      "source": [
        "sub_data = pd.concat([pos, neg])\n",
        "print(sub_data.shape)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(270350, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtE8_xnIX5wP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9b68a963-5556-42f7-effb-9cad57bcaec9"
      },
      "source": [
        "print(sub_data[sub_data['is_duplicate']==1].shape[0])\n",
        "print(sub_data[sub_data['is_duplicate']==0].shape[0])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "135175\n",
            "135175\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVZP8CEEjJTD",
        "colab_type": "text"
      },
      "source": [
        "# Splitting into training and validation data sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlT-Libv7vtn",
        "colab_type": "code",
        "outputId": "e1f1a253-5a26-4494-e547-ca0540f6ff05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(np.array(sub_data[['question1','question2']]),\n",
        "                                                    np.array(sub_data[['is_duplicate']]), test_size=0.2, \n",
        "                                                    random_state=42)\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(216280, 2) (216280, 1)\n",
            "(54070, 2) (54070, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ov5qrjWC-15B",
        "colab_type": "code",
        "outputId": "19a72cac-626b-4a79-c5d8-a401b4577415",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "X1_train = X_train[:,0]\n",
        "X2_train = X_train[:,1]\n",
        "\n",
        "X1_test = X_test[:,0]\n",
        "X2_test = X_test[:,1]\n",
        "\n",
        "print(X1_train.shape, X2_train.shape)\n",
        "print(X1_test.shape, X2_test.shape)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(216280,) (216280,)\n",
            "(54070,) (54070,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_4HRtq6BgV-",
        "colab_type": "text"
      },
      "source": [
        "# Loading glove vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzrkqZsUAVuE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_glove_vecs(glove_file):\n",
        "    with open(glove_file, 'r') as f:\n",
        "        words = set()\n",
        "        word_to_vec_map = {}\n",
        "        for line in f:\n",
        "            line = line.strip().split()\n",
        "            curr_word = line[0]\n",
        "            words.add(curr_word)\n",
        "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
        "        \n",
        "        i = 1\n",
        "        words_to_index = {}\n",
        "        index_to_words = {}\n",
        "        for w in sorted(words):\n",
        "            words_to_index[w] = i\n",
        "            index_to_words[i] = w\n",
        "            i = i + 1\n",
        "    return words_to_index, index_to_words, word_to_vec_map"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVgRliiqAc16",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('/content/drive/My Drive/toxicity/glove.6B.300d.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1h0v7imbAqqF",
        "colab_type": "code",
        "outputId": "f512d69c-443c-4863-a37b-b8473e7e99a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "max_len = 0\n",
        "avg_len = 0\n",
        "num = 0\n",
        "for i in sub_data.question1:\n",
        "  try:\n",
        "    tmp = len(i.translate(str.maketrans('','',string.punctuation)).lower().split())\n",
        "    num+=1\n",
        "    avg_len += tmp\n",
        "    if tmp>max_len:\n",
        "      max_len = tmp\n",
        "  except:\n",
        "    print(num,i)\n",
        "\n",
        "for i in sub_data.question2:\n",
        "  try:\n",
        "    tmp = len(i.translate(str.maketrans('','',string.punctuation)).lower().split())\n",
        "    num+=1\n",
        "    avg_len += tmp\n",
        "    if tmp>max_len:\n",
        "      max_len = tmp\n",
        "  except:\n",
        "    print(num,i)\n",
        "\n",
        "avg_len = avg_len/num\n",
        "print(max_len)\n",
        "print(avg_len)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "237\n",
            "10.789657850933974\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JODnqhQ_jVxZ",
        "colab_type": "text"
      },
      "source": [
        "# Converting words to word indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xm52MdLBG0B2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sentences_to_indices(X, word_to_index, seq_len):\n",
        "    m = X.shape[0]                                \n",
        "    X_indices = np.zeros((m, seq_len))\n",
        "    \n",
        "    for i in range(m): \n",
        "        tmp = X[i].translate(str.maketrans('','',string.punctuation)).lower().split()\n",
        "        j = 0\n",
        "        start_index =seq_len-len(tmp)\n",
        "        if start_index<0:\n",
        "          start_index =0\n",
        "        for w in tmp:\n",
        "          if j>= seq_len:\n",
        "            break\n",
        "          try:\n",
        "            X_indices[i, start_index+j] = word_to_index[w]\n",
        "            j = j+1\n",
        "          except KeyError:\n",
        "            pass\n",
        "            \n",
        "    \n",
        "    return X_indices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtASiwMvHGAc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "bb38cb41-2600-4b86-825d-5776a8384c47"
      },
      "source": [
        "X1_train_indices = sentences_to_indices(X1_train,word_to_index, 25)\n",
        "X2_train_indices = sentences_to_indices(X2_train,word_to_index, 25)\n",
        "X1_test_indices = sentences_to_indices(X1_test,word_to_index, 25)\n",
        "X2_test_indices = sentences_to_indices(X2_test,word_to_index, 25)\n",
        "print(X1_train_indices.shape)\n",
        "print(X2_train_indices.shape)\n",
        "print(X1_test_indices.shape)\n",
        "print(X2_test_indices.shape)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(216280, 25)\n",
            "(216280, 25)\n",
            "(54070, 25)\n",
            "(54070, 25)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBM065Wljf5H",
        "colab_type": "text"
      },
      "source": [
        "# Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTf4SuYoOtdx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
        "    vocab_len = len(word_to_index) + 1            \n",
        "    emb_dim = word_to_vec_map[\"cucumber\"].shape[0]  \n",
        "    emb_matrix = np.zeros((vocab_len, emb_dim))\n",
        "    for word, index in word_to_index.items():\n",
        "        emb_matrix[index, :] = word_to_vec_map[word]\n",
        "    embedding_layer = Embedding(vocab_len, emb_dim, trainable=False)\n",
        "    embedding_layer.build((None,))\n",
        "    embedding_layer.set_weights([emb_matrix])\n",
        "    \n",
        "    return embedding_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rdkl3ivyO-SA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "2b25b5ec-11ab-4019-f89d-f4d774715ab7"
      },
      "source": [
        "n_hidden = 64\n",
        "batch_size = 256\n",
        "n_epoch = 25\n",
        "\n",
        "def L1_distance(left, right):\n",
        "    return K.exp(-K.sum(K.abs(left-right), axis=1, keepdims=True))\n",
        "\n",
        "input1 = Input(shape=(None,))\n",
        "input2 = Input(shape=(None,))\n",
        "\n",
        "embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
        "\n",
        "encoded1 = embedding_layer(input1)\n",
        "encoded2 = embedding_layer(input2)\n",
        "\n",
        "shared_lstm = LSTM(n_hidden)\n",
        "\n",
        "output1 = shared_lstm(encoded1)\n",
        "output2 = shared_lstm(encoded2)\n",
        "\n",
        "l1_distance = Lambda(function=lambda x: L1_distance(x[0], x[1]),output_shape=lambda x: (x[0][0], 1))([output1, output2])\n",
        "\n",
        "l1_lstm = Model([input1, input2], [l1_distance])\n",
        "\n",
        "\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iv5qFMVlW5Se",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "59af7cc8-1348-4614-e2d1-cd18997fca5e"
      },
      "source": [
        "l1_lstm.summary()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 300)    120000300   input_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 64)           93440       embedding_1[0][0]                \n",
            "                                                                 embedding_1[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 1)            0           lstm_1[0][0]                     \n",
            "                                                                 lstm_1[1][0]                     \n",
            "==================================================================================================\n",
            "Total params: 120,093,740\n",
            "Trainable params: 93,440\n",
            "Non-trainable params: 120,000,300\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2UTuU9JU9d8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPiBn1syjngP",
        "colab_type": "text"
      },
      "source": [
        "# Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFHNOvqffL3K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2c3c8f35-6aef-4042-906a-471b1a4aec95"
      },
      "source": [
        "sgd = optimizers.SGD(lr=0.1, decay=1e-4, momentum=0.9, nesterov=True)\n",
        "l1_lstm.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy',f1_m])\n",
        "\n",
        "l1_lstm_trained = l1_lstm.fit([X1_train_indices, X2_train_indices], y_train, batch_size=batch_size, nb_epoch=n_epoch,\n",
        "                            validation_data=([X1_test_indices, X2_test_indices], y_test))#,class_weight={0:0.3,1:0.7}\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 216280 samples, validate on 54070 samples\n",
            "Epoch 1/25\n",
            "216280/216280 [==============================] - 64s 297us/step - loss: 0.6306 - acc: 0.7114 - f1_m: 0.6797 - val_loss: 0.5711 - val_acc: 0.7484 - val_f1_m: 0.7454\n",
            "Epoch 2/25\n",
            "216280/216280 [==============================] - 62s 289us/step - loss: 0.5574 - acc: 0.7580 - f1_m: 0.7500 - val_loss: 0.5478 - val_acc: 0.7663 - val_f1_m: 0.7611\n",
            "Epoch 3/25\n",
            "216280/216280 [==============================] - 62s 286us/step - loss: 0.5384 - acc: 0.7715 - f1_m: 0.7662 - val_loss: 0.5372 - val_acc: 0.7742 - val_f1_m: 0.7734\n",
            "Epoch 4/25\n",
            "216280/216280 [==============================] - 62s 287us/step - loss: 0.5262 - acc: 0.7808 - f1_m: 0.7768 - val_loss: 0.5294 - val_acc: 0.7747 - val_f1_m: 0.7622\n",
            "Epoch 5/25\n",
            "216280/216280 [==============================] - 62s 285us/step - loss: 0.5169 - acc: 0.7874 - f1_m: 0.7842 - val_loss: 0.5220 - val_acc: 0.7826 - val_f1_m: 0.7852\n",
            "Epoch 6/25\n",
            "216280/216280 [==============================] - 62s 284us/step - loss: 0.5097 - acc: 0.7914 - f1_m: 0.7890 - val_loss: 0.5158 - val_acc: 0.7833 - val_f1_m: 0.7777\n",
            "Epoch 7/25\n",
            "216280/216280 [==============================] - 61s 282us/step - loss: 0.5042 - acc: 0.7951 - f1_m: 0.7929 - val_loss: 0.5142 - val_acc: 0.7815 - val_f1_m: 0.7730\n",
            "Epoch 8/25\n",
            "216280/216280 [==============================] - 62s 286us/step - loss: 0.4991 - acc: 0.7982 - f1_m: 0.7963 - val_loss: 0.5120 - val_acc: 0.7890 - val_f1_m: 0.7900\n",
            "Epoch 9/25\n",
            "216280/216280 [==============================] - 62s 288us/step - loss: 0.4961 - acc: 0.7995 - f1_m: 0.7980 - val_loss: 0.5079 - val_acc: 0.7894 - val_f1_m: 0.7895\n",
            "Epoch 10/25\n",
            "216280/216280 [==============================] - 62s 289us/step - loss: 0.4923 - acc: 0.8013 - f1_m: 0.8000 - val_loss: 0.5060 - val_acc: 0.7872 - val_f1_m: 0.7823\n",
            "Epoch 11/25\n",
            "216280/216280 [==============================] - 62s 286us/step - loss: 0.4877 - acc: 0.8036 - f1_m: 0.8023 - val_loss: 0.5029 - val_acc: 0.7921 - val_f1_m: 0.7897\n",
            "Epoch 12/25\n",
            "216280/216280 [==============================] - 62s 286us/step - loss: 0.4849 - acc: 0.8057 - f1_m: 0.8045 - val_loss: 0.5023 - val_acc: 0.7915 - val_f1_m: 0.7893\n",
            "Epoch 13/25\n",
            "216280/216280 [==============================] - 61s 282us/step - loss: 0.4824 - acc: 0.8067 - f1_m: 0.8055 - val_loss: 0.4992 - val_acc: 0.7946 - val_f1_m: 0.7922\n",
            "Epoch 14/25\n",
            "216280/216280 [==============================] - 62s 285us/step - loss: 0.4796 - acc: 0.8084 - f1_m: 0.8072 - val_loss: 0.4984 - val_acc: 0.7938 - val_f1_m: 0.7911\n",
            "Epoch 15/25\n",
            "216280/216280 [==============================] - 62s 289us/step - loss: 0.4773 - acc: 0.8094 - f1_m: 0.8081 - val_loss: 0.4980 - val_acc: 0.7949 - val_f1_m: 0.7963\n",
            "Epoch 16/25\n",
            "216280/216280 [==============================] - 62s 287us/step - loss: 0.4756 - acc: 0.8106 - f1_m: 0.8092 - val_loss: 0.4971 - val_acc: 0.7939 - val_f1_m: 0.7886\n",
            "Epoch 17/25\n",
            "216280/216280 [==============================] - 62s 287us/step - loss: 0.4739 - acc: 0.8110 - f1_m: 0.8096 - val_loss: 0.4969 - val_acc: 0.7935 - val_f1_m: 0.7883\n",
            "Epoch 18/25\n",
            "216280/216280 [==============================] - 61s 284us/step - loss: 0.4721 - acc: 0.8120 - f1_m: 0.8107 - val_loss: 0.4949 - val_acc: 0.7963 - val_f1_m: 0.7944\n",
            "Epoch 19/25\n",
            "216280/216280 [==============================] - 61s 284us/step - loss: 0.4705 - acc: 0.8131 - f1_m: 0.8120 - val_loss: 0.4935 - val_acc: 0.7972 - val_f1_m: 0.7948\n",
            "Epoch 20/25\n",
            "216280/216280 [==============================] - 60s 279us/step - loss: 0.4690 - acc: 0.8136 - f1_m: 0.8124 - val_loss: 0.4930 - val_acc: 0.7969 - val_f1_m: 0.7960\n",
            "Epoch 21/25\n",
            "216280/216280 [==============================] - 61s 283us/step - loss: 0.4675 - acc: 0.8145 - f1_m: 0.8132 - val_loss: 0.4920 - val_acc: 0.7979 - val_f1_m: 0.7959\n",
            "Epoch 22/25\n",
            "216280/216280 [==============================] - 62s 286us/step - loss: 0.4663 - acc: 0.8152 - f1_m: 0.8140 - val_loss: 0.4910 - val_acc: 0.7982 - val_f1_m: 0.7970\n",
            "Epoch 23/25\n",
            "216280/216280 [==============================] - 62s 286us/step - loss: 0.4650 - acc: 0.8156 - f1_m: 0.8144 - val_loss: 0.4911 - val_acc: 0.7979 - val_f1_m: 0.7970\n",
            "Epoch 24/25\n",
            "216280/216280 [==============================] - 61s 284us/step - loss: 0.4637 - acc: 0.8164 - f1_m: 0.8152 - val_loss: 0.4915 - val_acc: 0.7987 - val_f1_m: 0.7987\n",
            "Epoch 25/25\n",
            "216280/216280 [==============================] - 62s 285us/step - loss: 0.4628 - acc: 0.8167 - f1_m: 0.8154 - val_loss: 0.4901 - val_acc: 0.7986 - val_f1_m: 0.7951\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVBL8AOPjtkx",
        "colab_type": "text"
      },
      "source": [
        "# Saving the model after removing last layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsZLwRLIdC6r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model([input1, input2],[output1,output2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtyXjPkiakX7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6663820a-b229-4e73-a7d2-9da8a14730b5"
      },
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"/content/drive/My Drive/codes/quora/lstm_25e.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "model.save_weights(\"/content/drive/My Drive/codes/quora/lstm_25e.h5\")\n",
        "print(\"Saved model to disk\")\n",
        "\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}