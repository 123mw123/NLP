{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/glove6b/glove.6B.200d.txt\n",
      "/kaggle/input/glove6b/glove.6B.50d.txt\n",
      "/kaggle/input/glove6b/glove.6B.300d.txt\n",
      "/kaggle/input/glove6b/glove.6B.100d.txt\n",
      "/kaggle/input/entity-annotated-corpus/ner.csv\n",
      "/kaggle/input/entity-annotated-corpus/ner_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Glove Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "400000\n"
     ]
    }
   ],
   "source": [
    "GLOVE_DIR = '../input/glove6b/glove.6B.300d.txt'\n",
    "print(os.path.exists(GLOVE_DIR))\n",
    "def read_glove_vecs(glove_file):\n",
    "    with open(glove_file, 'r') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "        \n",
    "        i = 1\n",
    "        words_to_index = {}\n",
    "        index_to_words = {}\n",
    "        for w in sorted(words):\n",
    "            words_to_index[w] = i\n",
    "            index_to_words[i] = w\n",
    "            i = i + 1\n",
    "    return words_to_index, index_to_words, word_to_vec_map\n",
    "\n",
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs(GLOVE_DIR)\n",
    "print(len(word_to_vec_map))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1          NaN             of   IN   O\n",
       "2          NaN  demonstrators  NNS   O\n",
       "3          NaN           have  VBP   O\n",
       "4          NaN        marched  VBN   O"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../input/entity-annotated-corpus/ner_dataset.csv', encoding= 'unicode_escape')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping B-entity and I-entity to same entity. Training only on PER and GPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    \"B-per\":\"per\",\n",
    "    \"I-per\":\"per\",\n",
    "    \"B-eve\":\"O\",\n",
    "    \"I-eve\":\"O\",\n",
    "    \"B-org\":\"O\",\n",
    "    \"I-org\":\"O\",\n",
    "    \"B-art\":\"O\",\n",
    "    \"I-art\":\"O\",\n",
    "    \"B-nat\":\"O\",\n",
    "    \"I-nat\":\"O\",\n",
    "    \"B-gpe\":\"gpe\",\n",
    "    \"I-gpe\":\"gpe\",\n",
    "    \"B-geo\":\"gpe\",\n",
    "    \"I-geo\":\"gpe\",\n",
    "    \"B-tim\":\"O\",\n",
    "    \"I-tim\":\"O\",\n",
    "    \"O\":\"O\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "data['Word'] = data['Word'].str.translate(str.maketrans('','',string.punctuation))\n",
    "data['Word'] = data['Word'].str.lower()\n",
    "data['Tag'] = data['Tag'].map(label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute token2idx, idx2token, tag2idx, idx2tag\n",
    "\n",
    "Below code is from *https://www.kaggle.com/dvircohen0/ner-lstm?scriptVersionId=60236417&cellId=3*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpe 61126\n",
      "per 34241\n",
      "O 953208\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "count_tags = {}\n",
    "def get_dict_map(data, token_or_tag):\n",
    "    tok2idx = {}\n",
    "    idx2tok = {}\n",
    "    \n",
    "    if token_or_tag == 'token':\n",
    "        vocab = list(set(data['Word'].to_list()))\n",
    "    else:\n",
    "        vocab = list(set(data['Tag'].to_list()))\n",
    "        for i in vocab:\n",
    "            if i not in count_tags:\n",
    "                count_tags[i]=0\n",
    "        for i in data['Tag'].to_list():\n",
    "            count_tags[i] += 1\n",
    "            \n",
    "    for i in count_tags:\n",
    "        print(i, count_tags[i])\n",
    "    idx2tok = {idx:tok for  idx, tok in enumerate(vocab)}\n",
    "    tok2idx = {tok:idx for  idx, tok in enumerate(vocab)}\n",
    "        \n",
    "    return tok2idx, idx2tok\n",
    "\n",
    "\n",
    "token2idx, idx2token = get_dict_map(data, 'token')\n",
    "tag2idx, idx2tag = get_dict_map(data, 'tag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Word_idx</th>\n",
       "      <th>Tag_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>358481.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>268046.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>120649.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "      <td>174642.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "      <td>234138.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag  Word_idx  Tag_idx\n",
       "0  Sentence: 1      thousands  NNS   O  358481.0        2\n",
       "1          NaN             of   IN   O  268046.0        2\n",
       "2          NaN  demonstrators  NNS   O  120649.0        2\n",
       "3          NaN           have  VBP   O  174642.0        2\n",
       "4          NaN        marched  VBN   O  234138.0        2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Word_idx'] = data['Word'].map(word_to_index)\n",
    "data['Tag_idx'] = data['Tag'].map(tag2idx)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Word_idx</th>\n",
       "      <th>Tag_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>[thousands, of, demonstrators, have, marched, ...</td>\n",
       "      <td>[NNS, IN, NNS, VBP, VBN, IN, NNP, TO, VB, DT, ...</td>\n",
       "      <td>[O, O, O, O, O, O, gpe, O, O, O, O, O, gpe, O,...</td>\n",
       "      <td>[358481.0, 268046.0, 120649.0, 174642.0, 23413...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 10</td>\n",
       "      <td>[iranian, officials, say, they, expect, to, ge...</td>\n",
       "      <td>[JJ, NNS, VBP, PRP, VBP, TO, VB, NN, TO, JJ, J...</td>\n",
       "      <td>[gpe, O, O, O, O, O, O, O, O, O, O, O, O, O, O...</td>\n",
       "      <td>[192569.0, 268225.0, 319691.0, 357810.0, 14275...</td>\n",
       "      <td>[0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 100</td>\n",
       "      <td>[helicopter, gunships, saturday, pounded, mili...</td>\n",
       "      <td>[NN, NNS, NNP, VBD, JJ, NNS, IN, DT, NNP, JJ, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, gpe, O, O, O, O, O, O...</td>\n",
       "      <td>[176329.0, 169259.0, 319134.0, 290058.0, 24443...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1000</td>\n",
       "      <td>[they, left, after, a, tense, hourlong, stando...</td>\n",
       "      <td>[PRP, VBD, IN, DT, NN, JJ, NN, IN, NN, NNS, .]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[357810.0, 219577.0, 47798.0, 43010.0, 355882....</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 10000</td>\n",
       "      <td>[un, relief, coordinator, jan, egeland, said, ...</td>\n",
       "      <td>[NNP, NN, NN, NNP, NNP, VBD, NNP, ,, NNP, ,, J...</td>\n",
       "      <td>[gpe, O, O, per, per, O, O, O, gpe, O, gpe, O,...</td>\n",
       "      <td>[370622.0, 305053.0, 108674.0, 195458.0, 13404...</td>\n",
       "      <td>[0, 2, 2, 1, 1, 2, 2, 2, 0, 2, 0, 2, 0, 2, 2, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sentence #                                               Word  \\\n",
       "0      Sentence: 1  [thousands, of, demonstrators, have, marched, ...   \n",
       "1     Sentence: 10  [iranian, officials, say, they, expect, to, ge...   \n",
       "2    Sentence: 100  [helicopter, gunships, saturday, pounded, mili...   \n",
       "3   Sentence: 1000  [they, left, after, a, tense, hourlong, stando...   \n",
       "4  Sentence: 10000  [un, relief, coordinator, jan, egeland, said, ...   \n",
       "\n",
       "                                                 POS  \\\n",
       "0  [NNS, IN, NNS, VBP, VBN, IN, NNP, TO, VB, DT, ...   \n",
       "1  [JJ, NNS, VBP, PRP, VBP, TO, VB, NN, TO, JJ, J...   \n",
       "2  [NN, NNS, NNP, VBD, JJ, NNS, IN, DT, NNP, JJ, ...   \n",
       "3     [PRP, VBD, IN, DT, NN, JJ, NN, IN, NN, NNS, .]   \n",
       "4  [NNP, NN, NN, NNP, NNP, VBD, NNP, ,, NNP, ,, J...   \n",
       "\n",
       "                                                 Tag  \\\n",
       "0  [O, O, O, O, O, O, gpe, O, O, O, O, O, gpe, O,...   \n",
       "1  [gpe, O, O, O, O, O, O, O, O, O, O, O, O, O, O...   \n",
       "2  [O, O, O, O, O, O, O, O, gpe, O, O, O, O, O, O...   \n",
       "3                  [O, O, O, O, O, O, O, O, O, O, O]   \n",
       "4  [gpe, O, O, per, per, O, O, O, gpe, O, gpe, O,...   \n",
       "\n",
       "                                            Word_idx  \\\n",
       "0  [358481.0, 268046.0, 120649.0, 174642.0, 23413...   \n",
       "1  [192569.0, 268225.0, 319691.0, 357810.0, 14275...   \n",
       "2  [176329.0, 169259.0, 319134.0, 290058.0, 24443...   \n",
       "3  [357810.0, 219577.0, 47798.0, 43010.0, 355882....   \n",
       "4  [370622.0, 305053.0, 108674.0, 195458.0, 13404...   \n",
       "\n",
       "                                             Tag_idx  \n",
       "0  [2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, ...  \n",
       "1  [0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...  \n",
       "2  [2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, ...  \n",
       "3                  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]  \n",
       "4  [0, 2, 2, 1, 1, 2, 2, 2, 0, 2, 0, 2, 0, 2, 2, ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fillna = data.fillna(method='ffill', axis=0)\n",
    "data_group = data_fillna.groupby(\n",
    "['Sentence #'],as_index=False\n",
    ")[['Word', 'POS', 'Tag', 'Word_idx', 'Tag_idx']].agg(lambda x: list(x))\n",
    "data_group.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into train and test set in 8:2 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47959 47959\n"
     ]
    }
   ],
   "source": [
    "tokens = data_group['Word_idx'].tolist()\n",
    "tags = data_group['Tag_idx'].tolist()\n",
    "print(len(tokens), len(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size 45561\n",
      "Val set size 2398\n"
     ]
    }
   ],
   "source": [
    "train_tokens = []\n",
    "val_tokens = []\n",
    "train_tags = []\n",
    "val_tags = []\n",
    "indices = list(range(len(tokens)))\n",
    "random.shuffle(indices)\n",
    "for i in indices:\n",
    "    assert len(tokens[i]) == len(tags[i])\n",
    "    if i%20!=0:\n",
    "        train_tokens.append(tokens[i])\n",
    "        train_tags.append(tags[i])\n",
    "    else:\n",
    "        val_tokens.append(tokens[i])\n",
    "        val_tags.append(tags[i])\n",
    "print(\"Train set size\", len(train_tokens))\n",
    "print(\"Val set size\", len(val_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000 3\n"
     ]
    }
   ],
   "source": [
    "unique_tokens = len(word_to_index) # len(list(set(data['Word'].to_list())))\n",
    "unique_tags = len(list(set(data['Tag'].to_list())))\n",
    "PAD_IDX = unique_tokens+1\n",
    "print(unique_tokens, unique_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Iterator\n",
    "\n",
    "Pad the input using PAD_IDX. Pad the output with -1. After this function all the sequences within a batch will have same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_iterator(tokens, tags, batch_size, shuffle=False):\n",
    "    order = list(range(len(tokens)))\n",
    "    for i in range((len(tokens)+1)//batch_size):\n",
    "        batch_sentences = [tokens[idx] for idx in order[i*batch_size:(i+1)*batch_size]]\n",
    "        batch_tags = [tags[idx] for idx in order[i*batch_size:(i+1)*batch_size]]\n",
    "        \n",
    "        batch_max_len = max([len(s) for s in batch_sentences])\n",
    "\n",
    "        batch_data = PAD_IDX*np.ones((len(batch_sentences), batch_max_len))\n",
    "        batch_labels = -1*np.ones((len(batch_sentences), batch_max_len))\n",
    "\n",
    "        for j in range(len(batch_sentences)):\n",
    "            cur_len = len(batch_sentences[j])\n",
    "            batch_data[j][:cur_len] = batch_sentences[j]\n",
    "            batch_labels[j][:cur_len] = batch_tags[j]\n",
    "\n",
    "        batch_data, batch_labels = torch.LongTensor(batch_data), torch.LongTensor(batch_labels)\n",
    "        batch_data = batch_data.transpose(0, 1).contiguous()\n",
    "        batch_labels = batch_labels.transpose(0, 1).contiguous()\n",
    "    \n",
    "        batch_data, batch_labels = batch_data.cuda(), batch_labels.cuda()\n",
    "        yield batch_data, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([26, 4]) torch.Size([26, 4])\n"
     ]
    }
   ],
   "source": [
    "train_data_iterator =  data_iterator(train_tokens, train_tags,4, shuffle=True)\n",
    "train_batch, labels_batch = next(train_data_iterator)\n",
    "print(train_batch.shape, labels_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Glove Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400002, 300)\n"
     ]
    }
   ],
   "source": [
    "vocab_len = len(word_to_index) + 2            \n",
    "emb_dim = word_to_vec_map[\"cucumber\"].shape[0]  \n",
    "emb_matrix = np.zeros((vocab_len, emb_dim))\n",
    "for word, index in word_to_index.items():\n",
    "    emb_matrix[index, :] = word_to_vec_map[word]\n",
    "print(emb_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_matrix = torch.FloatTensor(emb_matrix)\n",
    "embedding = torch.nn.Embedding.from_pretrained(emb_matrix,freeze=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, num_heads, hidden_dim, num_layers, num_labels, pad_idx, dropout=0.5, device=\"cuda\"):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.encoder = embedding # nn.Embedding(vocab_size, embedding_size)\n",
    "        self.pos_encoder = PositionalEncoding(embedding_size, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(embedding_size, num_heads, hidden_dim, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, num_layers)\n",
    "        self.fc_out = nn.Linear(embedding_size, num_labels)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.pad_idx = pad_idx\n",
    "        self.embedding_size = embedding_size\n",
    "        self.device = device\n",
    "\n",
    "\n",
    "    def make_src_mask(self, src):\n",
    "        # use src_mask to ignore pad indices embeddings while computing self-attention output\n",
    "        src_mask = src.transpose(0, 1) == self.pad_idx\n",
    "        return src_mask.to(self.device)\n",
    "\n",
    "    def forward(self, src):\n",
    "        src_mask = self.make_src_mask(src)\n",
    "        src = self.encoder(src) * math.sqrt(self.embedding_size)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, src_key_padding_mask=src_mask)\n",
    "        output = self.fc_out(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "vocab_size = len(word_to_index) + 2\n",
    "num_classes = unique_tags\n",
    "embedding_size = 300\n",
    "num_heads = 6\n",
    "num_layers = 6\n",
    "dropout = 0.0\n",
    "hidden_dim = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerModel(vocab_size, embedding_size, num_heads,hidden_dim, num_layers, num_classes, PAD_IDX, dropout, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchsummaryX\n",
      "  Downloading torchsummaryX-1.3.0-py3-none-any.whl (3.6 kB)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from torchsummaryX) (1.7.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchsummaryX) (1.19.5)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from torchsummaryX) (1.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->torchsummaryX) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas->torchsummaryX) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->torchsummaryX) (1.15.0)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch->torchsummaryX) (0.18.2)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch->torchsummaryX) (3.7.4.3)\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch->torchsummaryX) (0.6)\n",
      "Installing collected packages: torchsummaryX\n",
      "Successfully installed torchsummaryX-1.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummaryX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================================================================\n",
      "                                                   Kernel Shape  \\\n",
      "Layer                                                             \n",
      "0_encoder                                         [300, 400002]   \n",
      "1_pos_encoder.Dropout_dropout                                 -   \n",
      "2_transformer_encoder.layers.0.Dropout_dropout1               -   \n",
      "3_transformer_encoder.layers.0.LayerNorm_norm1            [300]   \n",
      "4_transformer_encoder.layers.0.Linear_linear1       [300, 2048]   \n",
      "5_transformer_encoder.layers.0.Dropout_dropout                -   \n",
      "6_transformer_encoder.layers.0.Linear_linear2       [2048, 300]   \n",
      "7_transformer_encoder.layers.0.Dropout_dropout2               -   \n",
      "8_transformer_encoder.layers.0.LayerNorm_norm2            [300]   \n",
      "9_transformer_encoder.layers.1.Dropout_dropout1               -   \n",
      "10_transformer_encoder.layers.1.LayerNorm_norm1           [300]   \n",
      "11_transformer_encoder.layers.1.Linear_linear1      [300, 2048]   \n",
      "12_transformer_encoder.layers.1.Dropout_dropout               -   \n",
      "13_transformer_encoder.layers.1.Linear_linear2      [2048, 300]   \n",
      "14_transformer_encoder.layers.1.Dropout_dropout2              -   \n",
      "15_transformer_encoder.layers.1.LayerNorm_norm2           [300]   \n",
      "16_transformer_encoder.layers.2.Dropout_dropout1              -   \n",
      "17_transformer_encoder.layers.2.LayerNorm_norm1           [300]   \n",
      "18_transformer_encoder.layers.2.Linear_linear1      [300, 2048]   \n",
      "19_transformer_encoder.layers.2.Dropout_dropout               -   \n",
      "20_transformer_encoder.layers.2.Linear_linear2      [2048, 300]   \n",
      "21_transformer_encoder.layers.2.Dropout_dropout2              -   \n",
      "22_transformer_encoder.layers.2.LayerNorm_norm2           [300]   \n",
      "23_transformer_encoder.layers.3.Dropout_dropout1              -   \n",
      "24_transformer_encoder.layers.3.LayerNorm_norm1           [300]   \n",
      "25_transformer_encoder.layers.3.Linear_linear1      [300, 2048]   \n",
      "26_transformer_encoder.layers.3.Dropout_dropout               -   \n",
      "27_transformer_encoder.layers.3.Linear_linear2      [2048, 300]   \n",
      "28_transformer_encoder.layers.3.Dropout_dropout2              -   \n",
      "29_transformer_encoder.layers.3.LayerNorm_norm2           [300]   \n",
      "30_transformer_encoder.layers.4.Dropout_dropout1              -   \n",
      "31_transformer_encoder.layers.4.LayerNorm_norm1           [300]   \n",
      "32_transformer_encoder.layers.4.Linear_linear1      [300, 2048]   \n",
      "33_transformer_encoder.layers.4.Dropout_dropout               -   \n",
      "34_transformer_encoder.layers.4.Linear_linear2      [2048, 300]   \n",
      "35_transformer_encoder.layers.4.Dropout_dropout2              -   \n",
      "36_transformer_encoder.layers.4.LayerNorm_norm2           [300]   \n",
      "37_transformer_encoder.layers.5.Dropout_dropout1              -   \n",
      "38_transformer_encoder.layers.5.LayerNorm_norm1           [300]   \n",
      "39_transformer_encoder.layers.5.Linear_linear1      [300, 2048]   \n",
      "40_transformer_encoder.layers.5.Dropout_dropout               -   \n",
      "41_transformer_encoder.layers.5.Linear_linear2      [2048, 300]   \n",
      "42_transformer_encoder.layers.5.Dropout_dropout2              -   \n",
      "43_transformer_encoder.layers.5.LayerNorm_norm2           [300]   \n",
      "44_fc_out                                              [300, 3]   \n",
      "\n",
      "                                                   Output Shape    Params  \\\n",
      "Layer                                                                       \n",
      "0_encoder                                          [20, 4, 300]         -   \n",
      "1_pos_encoder.Dropout_dropout                      [20, 4, 300]         -   \n",
      "2_transformer_encoder.layers.0.Dropout_dropout1    [20, 4, 300]         -   \n",
      "3_transformer_encoder.layers.0.LayerNorm_norm1     [20, 4, 300]     600.0   \n",
      "4_transformer_encoder.layers.0.Linear_linear1     [20, 4, 2048]  616.448k   \n",
      "5_transformer_encoder.layers.0.Dropout_dropout    [20, 4, 2048]         -   \n",
      "6_transformer_encoder.layers.0.Linear_linear2      [20, 4, 300]    614.7k   \n",
      "7_transformer_encoder.layers.0.Dropout_dropout2    [20, 4, 300]         -   \n",
      "8_transformer_encoder.layers.0.LayerNorm_norm2     [20, 4, 300]     600.0   \n",
      "9_transformer_encoder.layers.1.Dropout_dropout1    [20, 4, 300]         -   \n",
      "10_transformer_encoder.layers.1.LayerNorm_norm1    [20, 4, 300]     600.0   \n",
      "11_transformer_encoder.layers.1.Linear_linear1    [20, 4, 2048]  616.448k   \n",
      "12_transformer_encoder.layers.1.Dropout_dropout   [20, 4, 2048]         -   \n",
      "13_transformer_encoder.layers.1.Linear_linear2     [20, 4, 300]    614.7k   \n",
      "14_transformer_encoder.layers.1.Dropout_dropout2   [20, 4, 300]         -   \n",
      "15_transformer_encoder.layers.1.LayerNorm_norm2    [20, 4, 300]     600.0   \n",
      "16_transformer_encoder.layers.2.Dropout_dropout1   [20, 4, 300]         -   \n",
      "17_transformer_encoder.layers.2.LayerNorm_norm1    [20, 4, 300]     600.0   \n",
      "18_transformer_encoder.layers.2.Linear_linear1    [20, 4, 2048]  616.448k   \n",
      "19_transformer_encoder.layers.2.Dropout_dropout   [20, 4, 2048]         -   \n",
      "20_transformer_encoder.layers.2.Linear_linear2     [20, 4, 300]    614.7k   \n",
      "21_transformer_encoder.layers.2.Dropout_dropout2   [20, 4, 300]         -   \n",
      "22_transformer_encoder.layers.2.LayerNorm_norm2    [20, 4, 300]     600.0   \n",
      "23_transformer_encoder.layers.3.Dropout_dropout1   [20, 4, 300]         -   \n",
      "24_transformer_encoder.layers.3.LayerNorm_norm1    [20, 4, 300]     600.0   \n",
      "25_transformer_encoder.layers.3.Linear_linear1    [20, 4, 2048]  616.448k   \n",
      "26_transformer_encoder.layers.3.Dropout_dropout   [20, 4, 2048]         -   \n",
      "27_transformer_encoder.layers.3.Linear_linear2     [20, 4, 300]    614.7k   \n",
      "28_transformer_encoder.layers.3.Dropout_dropout2   [20, 4, 300]         -   \n",
      "29_transformer_encoder.layers.3.LayerNorm_norm2    [20, 4, 300]     600.0   \n",
      "30_transformer_encoder.layers.4.Dropout_dropout1   [20, 4, 300]         -   \n",
      "31_transformer_encoder.layers.4.LayerNorm_norm1    [20, 4, 300]     600.0   \n",
      "32_transformer_encoder.layers.4.Linear_linear1    [20, 4, 2048]  616.448k   \n",
      "33_transformer_encoder.layers.4.Dropout_dropout   [20, 4, 2048]         -   \n",
      "34_transformer_encoder.layers.4.Linear_linear2     [20, 4, 300]    614.7k   \n",
      "35_transformer_encoder.layers.4.Dropout_dropout2   [20, 4, 300]         -   \n",
      "36_transformer_encoder.layers.4.LayerNorm_norm2    [20, 4, 300]     600.0   \n",
      "37_transformer_encoder.layers.5.Dropout_dropout1   [20, 4, 300]         -   \n",
      "38_transformer_encoder.layers.5.LayerNorm_norm1    [20, 4, 300]     600.0   \n",
      "39_transformer_encoder.layers.5.Linear_linear1    [20, 4, 2048]  616.448k   \n",
      "40_transformer_encoder.layers.5.Dropout_dropout   [20, 4, 2048]         -   \n",
      "41_transformer_encoder.layers.5.Linear_linear2     [20, 4, 300]    614.7k   \n",
      "42_transformer_encoder.layers.5.Dropout_dropout2   [20, 4, 300]         -   \n",
      "43_transformer_encoder.layers.5.LayerNorm_norm2    [20, 4, 300]     600.0   \n",
      "44_fc_out                                            [20, 4, 3]     903.0   \n",
      "\n",
      "                                                 Mult-Adds  \n",
      "Layer                                                       \n",
      "0_encoder                                                -  \n",
      "1_pos_encoder.Dropout_dropout                            -  \n",
      "2_transformer_encoder.layers.0.Dropout_dropout1          -  \n",
      "3_transformer_encoder.layers.0.LayerNorm_norm1       300.0  \n",
      "4_transformer_encoder.layers.0.Linear_linear1       614.4k  \n",
      "5_transformer_encoder.layers.0.Dropout_dropout           -  \n",
      "6_transformer_encoder.layers.0.Linear_linear2       614.4k  \n",
      "7_transformer_encoder.layers.0.Dropout_dropout2          -  \n",
      "8_transformer_encoder.layers.0.LayerNorm_norm2       300.0  \n",
      "9_transformer_encoder.layers.1.Dropout_dropout1          -  \n",
      "10_transformer_encoder.layers.1.LayerNorm_norm1      300.0  \n",
      "11_transformer_encoder.layers.1.Linear_linear1      614.4k  \n",
      "12_transformer_encoder.layers.1.Dropout_dropout          -  \n",
      "13_transformer_encoder.layers.1.Linear_linear2      614.4k  \n",
      "14_transformer_encoder.layers.1.Dropout_dropout2         -  \n",
      "15_transformer_encoder.layers.1.LayerNorm_norm2      300.0  \n",
      "16_transformer_encoder.layers.2.Dropout_dropout1         -  \n",
      "17_transformer_encoder.layers.2.LayerNorm_norm1      300.0  \n",
      "18_transformer_encoder.layers.2.Linear_linear1      614.4k  \n",
      "19_transformer_encoder.layers.2.Dropout_dropout          -  \n",
      "20_transformer_encoder.layers.2.Linear_linear2      614.4k  \n",
      "21_transformer_encoder.layers.2.Dropout_dropout2         -  \n",
      "22_transformer_encoder.layers.2.LayerNorm_norm2      300.0  \n",
      "23_transformer_encoder.layers.3.Dropout_dropout1         -  \n",
      "24_transformer_encoder.layers.3.LayerNorm_norm1      300.0  \n",
      "25_transformer_encoder.layers.3.Linear_linear1      614.4k  \n",
      "26_transformer_encoder.layers.3.Dropout_dropout          -  \n",
      "27_transformer_encoder.layers.3.Linear_linear2      614.4k  \n",
      "28_transformer_encoder.layers.3.Dropout_dropout2         -  \n",
      "29_transformer_encoder.layers.3.LayerNorm_norm2      300.0  \n",
      "30_transformer_encoder.layers.4.Dropout_dropout1         -  \n",
      "31_transformer_encoder.layers.4.LayerNorm_norm1      300.0  \n",
      "32_transformer_encoder.layers.4.Linear_linear1      614.4k  \n",
      "33_transformer_encoder.layers.4.Dropout_dropout          -  \n",
      "34_transformer_encoder.layers.4.Linear_linear2      614.4k  \n",
      "35_transformer_encoder.layers.4.Dropout_dropout2         -  \n",
      "36_transformer_encoder.layers.4.LayerNorm_norm2      300.0  \n",
      "37_transformer_encoder.layers.5.Dropout_dropout1         -  \n",
      "38_transformer_encoder.layers.5.LayerNorm_norm1      300.0  \n",
      "39_transformer_encoder.layers.5.Linear_linear1      614.4k  \n",
      "40_transformer_encoder.layers.5.Dropout_dropout          -  \n",
      "41_transformer_encoder.layers.5.Linear_linear2      614.4k  \n",
      "42_transformer_encoder.layers.5.Dropout_dropout2         -  \n",
      "43_transformer_encoder.layers.5.LayerNorm_norm2      300.0  \n",
      "44_fc_out                                            900.0  \n",
      "---------------------------------------------------------------------------------------------------\n",
      "                           Totals\n",
      "Total params          127.395591M\n",
      "Trainable params        7.394991M\n",
      "Non-trainable params    120.0006M\n",
      "Mult-Adds                 7.3773M\n",
      "===================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kernel Shape</th>\n",
       "      <th>Output Shape</th>\n",
       "      <th>Params</th>\n",
       "      <th>Mult-Adds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0_encoder</th>\n",
       "      <td>[300, 400002]</td>\n",
       "      <td>[20, 4, 300]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_pos_encoder.Dropout_dropout</th>\n",
       "      <td>-</td>\n",
       "      <td>[20, 4, 300]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_transformer_encoder.layers.0.Dropout_dropout1</th>\n",
       "      <td>-</td>\n",
       "      <td>[20, 4, 300]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_transformer_encoder.layers.0.LayerNorm_norm1</th>\n",
       "      <td>[300]</td>\n",
       "      <td>[20, 4, 300]</td>\n",
       "      <td>600.0</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_transformer_encoder.layers.0.Linear_linear1</th>\n",
       "      <td>[300, 2048]</td>\n",
       "      <td>[20, 4, 2048]</td>\n",
       "      <td>616448.0</td>\n",
       "      <td>614400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5_transformer_encoder.layers.0.Dropout_dropout</th>\n",
       "      <td>-</td>\n",
       "      <td>[20, 4, 2048]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_transformer_encoder.layers.0.Linear_linear2</th>\n",
       "      <td>[2048, 300]</td>\n",
       "      <td>[20, 4, 300]</td>\n",
       "      <td>614700.0</td>\n",
       "      <td>614400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7_transformer_encoder.layers.0.Dropout_dropout2</th>\n",
       "      <td>-</td>\n",
       "      <td>[20, 4, 300]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8_transformer_encoder.layers.0.LayerNorm_norm2</th>\n",
       "      <td>[300]</td>\n",
       "      <td>[20, 4, 300]</td>\n",
       "      <td>600.0</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9_transformer_encoder.layers.1.Dropout_dropout1</th>\n",
       "      <td>-</td>\n",
       "      <td>[20, 4, 300]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10_transformer_encoder.layers.1.LayerNorm_norm1</th>\n",
       "      <td>[300]</td>\n",
       "      <td>[20, 4, 300]</td>\n",
       "      <td>600.0</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11_transformer_encoder.layers.1.Linear_linear1</th>\n",
       "      <td>[300, 2048]</td>\n",
       "      <td>[20, 4, 2048]</td>\n",
       "      <td>616448.0</td>\n",
       "      <td>614400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12_transformer_encoder.layers.1.Dropout_dropout</th>\n",
       "      <td>-</td>\n",
       "      <td>[20, 4, 2048]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13_transformer_encoder.layers.1.Linear_linear2</th>\n",
       "      <td>[2048, 300]</td>\n",
       "      <td>[20, 4, 300]</td>\n",
       "      <td>614700.0</td>\n",
       "      <td>614400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14_transformer_encoder.layers.1.Dropout_dropout2</th>\n",
       "      <td>-</td>\n",
       "      <td>[20, 4, 300]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15_transformer_encoder.layers.1.LayerNorm_norm2</th>\n",
       "      <td>[300]</td>\n",
       "      <td>[20, 4, 300]</td>\n",
       "      <td>600.0</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16_transformer_encoder.layers.2.Dropout_dropout1</th>\n",
       "      <td>-</td>\n",
       "      <td>[20, 4, 300]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17_transformer_encoder.layers.2.LayerNorm_norm1</th>\n",
       "      <td>[300]</td>\n",
       "      <td>[20, 4, 300]</td>\n",
       "      <td>600.0</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18_transformer_encoder.layers.2.Linear_linear1</th>\n",
       "      <td>[300, 2048]</td>\n",
       "      <td>[20, 4, 2048]</td>\n",
       "      <td>616448.0</td>\n",
       "      <td>614400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19_transformer_encoder.layers.2.Dropout_dropout</th>\n",
       "      <td>-</td>\n",
       "      <td>[20, 4, 2048]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20_transformer_encoder.layers.2.Linear_linear2</th>\n",
       "      <td>[2048, 300]</td>\n",
       "      <td>[20, 4, 300]</td>\n",
       "      <td>614700.0</td>\n",
       "      <td>614400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21_transformer_encoder.layers.2.Dropout_dropout2</th>\n",
       "      <td>-</td>\n",
       "      <td>[20, 4, 300]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22_transformer_encoder.layers.2.LayerNorm_norm2</th>\n",
       "      <td>[300]</td>\n",
       "      <td>[20, 4, 300]</td>\n",
       "      <td>600.0</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23_transformer_encoder.layers.3.Dropout_dropout1</th>\n",
       "      <td>-</td>\n",
       "      <td>[20, 4, 300]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24_transformer_encoder.layers.3.LayerNorm_norm1</th>\n",
       "      <td>[300]</td>\n",
       "      <td>[20, 4, 300]</td>\n",
       "      <td>600.0</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25_transformer_encoder.layers.3.Linear_linear1</th>\n",
       "      <td>[300, 2048]</td>\n",
       "      <td>[20, 4, 2048]</td>\n",
       "      <td>616448.0</td>\n",
       "      <td>614400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26_transformer_encoder.layers.3.Dropout_dropout</th>\n",
       "      <td>-</td>\n",
       "      <td>[20, 4, 2048]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27_transformer_encoder.layers.3.Linear_linear2</th>\n",
       "      <td>[2048, 300]</td>\n",
       "      <td>[20, 4, 300]</td>\n",
       "      <td>614700.0</td>\n",
       "      <td>614400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28_transformer_encoder.layers.3.Dropout_dropout2</th>\n",
       "      <td>-</td>\n",
       "      <td>[20, 4, 300]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29_transformer_encoder.layers.3.LayerNorm_norm2</th>\n",
       "      <td>[300]</td>\n",
       "      <td>[20, 4, 300]</td>\n",
       "      <td>600.0</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30_transformer_encoder.layers.4.Dropout_dropout1</th>\n",
       "      <td>-</td>\n",
       "      <td>[20, 4, 300]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31_transformer_encoder.layers.4.LayerNorm_norm1</th>\n",
       "      <td>[300]</td>\n",
       "      <td>[20, 4, 300]</td>\n",
       "      <td>600.0</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32_transformer_encoder.layers.4.Linear_linear1</th>\n",
       "      <td>[300, 2048]</td>\n",
       "      <td>[20, 4, 2048]</td>\n",
       "      <td>616448.0</td>\n",
       "      <td>614400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33_transformer_encoder.layers.4.Dropout_dropout</th>\n",
       "      <td>-</td>\n",
       "      <td>[20, 4, 2048]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34_transformer_encoder.layers.4.Linear_linear2</th>\n",
       "      <td>[2048, 300]</td>\n",
       "      <td>[20, 4, 300]</td>\n",
       "      <td>614700.0</td>\n",
       "      <td>614400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35_transformer_encoder.layers.4.Dropout_dropout2</th>\n",
       "      <td>-</td>\n",
       "      <td>[20, 4, 300]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36_transformer_encoder.layers.4.LayerNorm_norm2</th>\n",
       "      <td>[300]</td>\n",
       "      <td>[20, 4, 300]</td>\n",
       "      <td>600.0</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37_transformer_encoder.layers.5.Dropout_dropout1</th>\n",
       "      <td>-</td>\n",
       "      <td>[20, 4, 300]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38_transformer_encoder.layers.5.LayerNorm_norm1</th>\n",
       "      <td>[300]</td>\n",
       "      <td>[20, 4, 300]</td>\n",
       "      <td>600.0</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39_transformer_encoder.layers.5.Linear_linear1</th>\n",
       "      <td>[300, 2048]</td>\n",
       "      <td>[20, 4, 2048]</td>\n",
       "      <td>616448.0</td>\n",
       "      <td>614400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40_transformer_encoder.layers.5.Dropout_dropout</th>\n",
       "      <td>-</td>\n",
       "      <td>[20, 4, 2048]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41_transformer_encoder.layers.5.Linear_linear2</th>\n",
       "      <td>[2048, 300]</td>\n",
       "      <td>[20, 4, 300]</td>\n",
       "      <td>614700.0</td>\n",
       "      <td>614400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42_transformer_encoder.layers.5.Dropout_dropout2</th>\n",
       "      <td>-</td>\n",
       "      <td>[20, 4, 300]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43_transformer_encoder.layers.5.LayerNorm_norm2</th>\n",
       "      <td>[300]</td>\n",
       "      <td>[20, 4, 300]</td>\n",
       "      <td>600.0</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44_fc_out</th>\n",
       "      <td>[300, 3]</td>\n",
       "      <td>[20, 4, 3]</td>\n",
       "      <td>903.0</td>\n",
       "      <td>900.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Kernel Shape  \\\n",
       "Layer                                                             \n",
       "0_encoder                                         [300, 400002]   \n",
       "1_pos_encoder.Dropout_dropout                                 -   \n",
       "2_transformer_encoder.layers.0.Dropout_dropout1               -   \n",
       "3_transformer_encoder.layers.0.LayerNorm_norm1            [300]   \n",
       "4_transformer_encoder.layers.0.Linear_linear1       [300, 2048]   \n",
       "5_transformer_encoder.layers.0.Dropout_dropout                -   \n",
       "6_transformer_encoder.layers.0.Linear_linear2       [2048, 300]   \n",
       "7_transformer_encoder.layers.0.Dropout_dropout2               -   \n",
       "8_transformer_encoder.layers.0.LayerNorm_norm2            [300]   \n",
       "9_transformer_encoder.layers.1.Dropout_dropout1               -   \n",
       "10_transformer_encoder.layers.1.LayerNorm_norm1           [300]   \n",
       "11_transformer_encoder.layers.1.Linear_linear1      [300, 2048]   \n",
       "12_transformer_encoder.layers.1.Dropout_dropout               -   \n",
       "13_transformer_encoder.layers.1.Linear_linear2      [2048, 300]   \n",
       "14_transformer_encoder.layers.1.Dropout_dropout2              -   \n",
       "15_transformer_encoder.layers.1.LayerNorm_norm2           [300]   \n",
       "16_transformer_encoder.layers.2.Dropout_dropout1              -   \n",
       "17_transformer_encoder.layers.2.LayerNorm_norm1           [300]   \n",
       "18_transformer_encoder.layers.2.Linear_linear1      [300, 2048]   \n",
       "19_transformer_encoder.layers.2.Dropout_dropout               -   \n",
       "20_transformer_encoder.layers.2.Linear_linear2      [2048, 300]   \n",
       "21_transformer_encoder.layers.2.Dropout_dropout2              -   \n",
       "22_transformer_encoder.layers.2.LayerNorm_norm2           [300]   \n",
       "23_transformer_encoder.layers.3.Dropout_dropout1              -   \n",
       "24_transformer_encoder.layers.3.LayerNorm_norm1           [300]   \n",
       "25_transformer_encoder.layers.3.Linear_linear1      [300, 2048]   \n",
       "26_transformer_encoder.layers.3.Dropout_dropout               -   \n",
       "27_transformer_encoder.layers.3.Linear_linear2      [2048, 300]   \n",
       "28_transformer_encoder.layers.3.Dropout_dropout2              -   \n",
       "29_transformer_encoder.layers.3.LayerNorm_norm2           [300]   \n",
       "30_transformer_encoder.layers.4.Dropout_dropout1              -   \n",
       "31_transformer_encoder.layers.4.LayerNorm_norm1           [300]   \n",
       "32_transformer_encoder.layers.4.Linear_linear1      [300, 2048]   \n",
       "33_transformer_encoder.layers.4.Dropout_dropout               -   \n",
       "34_transformer_encoder.layers.4.Linear_linear2      [2048, 300]   \n",
       "35_transformer_encoder.layers.4.Dropout_dropout2              -   \n",
       "36_transformer_encoder.layers.4.LayerNorm_norm2           [300]   \n",
       "37_transformer_encoder.layers.5.Dropout_dropout1              -   \n",
       "38_transformer_encoder.layers.5.LayerNorm_norm1           [300]   \n",
       "39_transformer_encoder.layers.5.Linear_linear1      [300, 2048]   \n",
       "40_transformer_encoder.layers.5.Dropout_dropout               -   \n",
       "41_transformer_encoder.layers.5.Linear_linear2      [2048, 300]   \n",
       "42_transformer_encoder.layers.5.Dropout_dropout2              -   \n",
       "43_transformer_encoder.layers.5.LayerNorm_norm2           [300]   \n",
       "44_fc_out                                              [300, 3]   \n",
       "\n",
       "                                                   Output Shape    Params  \\\n",
       "Layer                                                                       \n",
       "0_encoder                                          [20, 4, 300]       NaN   \n",
       "1_pos_encoder.Dropout_dropout                      [20, 4, 300]       NaN   \n",
       "2_transformer_encoder.layers.0.Dropout_dropout1    [20, 4, 300]       NaN   \n",
       "3_transformer_encoder.layers.0.LayerNorm_norm1     [20, 4, 300]     600.0   \n",
       "4_transformer_encoder.layers.0.Linear_linear1     [20, 4, 2048]  616448.0   \n",
       "5_transformer_encoder.layers.0.Dropout_dropout    [20, 4, 2048]       NaN   \n",
       "6_transformer_encoder.layers.0.Linear_linear2      [20, 4, 300]  614700.0   \n",
       "7_transformer_encoder.layers.0.Dropout_dropout2    [20, 4, 300]       NaN   \n",
       "8_transformer_encoder.layers.0.LayerNorm_norm2     [20, 4, 300]     600.0   \n",
       "9_transformer_encoder.layers.1.Dropout_dropout1    [20, 4, 300]       NaN   \n",
       "10_transformer_encoder.layers.1.LayerNorm_norm1    [20, 4, 300]     600.0   \n",
       "11_transformer_encoder.layers.1.Linear_linear1    [20, 4, 2048]  616448.0   \n",
       "12_transformer_encoder.layers.1.Dropout_dropout   [20, 4, 2048]       NaN   \n",
       "13_transformer_encoder.layers.1.Linear_linear2     [20, 4, 300]  614700.0   \n",
       "14_transformer_encoder.layers.1.Dropout_dropout2   [20, 4, 300]       NaN   \n",
       "15_transformer_encoder.layers.1.LayerNorm_norm2    [20, 4, 300]     600.0   \n",
       "16_transformer_encoder.layers.2.Dropout_dropout1   [20, 4, 300]       NaN   \n",
       "17_transformer_encoder.layers.2.LayerNorm_norm1    [20, 4, 300]     600.0   \n",
       "18_transformer_encoder.layers.2.Linear_linear1    [20, 4, 2048]  616448.0   \n",
       "19_transformer_encoder.layers.2.Dropout_dropout   [20, 4, 2048]       NaN   \n",
       "20_transformer_encoder.layers.2.Linear_linear2     [20, 4, 300]  614700.0   \n",
       "21_transformer_encoder.layers.2.Dropout_dropout2   [20, 4, 300]       NaN   \n",
       "22_transformer_encoder.layers.2.LayerNorm_norm2    [20, 4, 300]     600.0   \n",
       "23_transformer_encoder.layers.3.Dropout_dropout1   [20, 4, 300]       NaN   \n",
       "24_transformer_encoder.layers.3.LayerNorm_norm1    [20, 4, 300]     600.0   \n",
       "25_transformer_encoder.layers.3.Linear_linear1    [20, 4, 2048]  616448.0   \n",
       "26_transformer_encoder.layers.3.Dropout_dropout   [20, 4, 2048]       NaN   \n",
       "27_transformer_encoder.layers.3.Linear_linear2     [20, 4, 300]  614700.0   \n",
       "28_transformer_encoder.layers.3.Dropout_dropout2   [20, 4, 300]       NaN   \n",
       "29_transformer_encoder.layers.3.LayerNorm_norm2    [20, 4, 300]     600.0   \n",
       "30_transformer_encoder.layers.4.Dropout_dropout1   [20, 4, 300]       NaN   \n",
       "31_transformer_encoder.layers.4.LayerNorm_norm1    [20, 4, 300]     600.0   \n",
       "32_transformer_encoder.layers.4.Linear_linear1    [20, 4, 2048]  616448.0   \n",
       "33_transformer_encoder.layers.4.Dropout_dropout   [20, 4, 2048]       NaN   \n",
       "34_transformer_encoder.layers.4.Linear_linear2     [20, 4, 300]  614700.0   \n",
       "35_transformer_encoder.layers.4.Dropout_dropout2   [20, 4, 300]       NaN   \n",
       "36_transformer_encoder.layers.4.LayerNorm_norm2    [20, 4, 300]     600.0   \n",
       "37_transformer_encoder.layers.5.Dropout_dropout1   [20, 4, 300]       NaN   \n",
       "38_transformer_encoder.layers.5.LayerNorm_norm1    [20, 4, 300]     600.0   \n",
       "39_transformer_encoder.layers.5.Linear_linear1    [20, 4, 2048]  616448.0   \n",
       "40_transformer_encoder.layers.5.Dropout_dropout   [20, 4, 2048]       NaN   \n",
       "41_transformer_encoder.layers.5.Linear_linear2     [20, 4, 300]  614700.0   \n",
       "42_transformer_encoder.layers.5.Dropout_dropout2   [20, 4, 300]       NaN   \n",
       "43_transformer_encoder.layers.5.LayerNorm_norm2    [20, 4, 300]     600.0   \n",
       "44_fc_out                                            [20, 4, 3]     903.0   \n",
       "\n",
       "                                                  Mult-Adds  \n",
       "Layer                                                        \n",
       "0_encoder                                               NaN  \n",
       "1_pos_encoder.Dropout_dropout                           NaN  \n",
       "2_transformer_encoder.layers.0.Dropout_dropout1         NaN  \n",
       "3_transformer_encoder.layers.0.LayerNorm_norm1        300.0  \n",
       "4_transformer_encoder.layers.0.Linear_linear1      614400.0  \n",
       "5_transformer_encoder.layers.0.Dropout_dropout          NaN  \n",
       "6_transformer_encoder.layers.0.Linear_linear2      614400.0  \n",
       "7_transformer_encoder.layers.0.Dropout_dropout2         NaN  \n",
       "8_transformer_encoder.layers.0.LayerNorm_norm2        300.0  \n",
       "9_transformer_encoder.layers.1.Dropout_dropout1         NaN  \n",
       "10_transformer_encoder.layers.1.LayerNorm_norm1       300.0  \n",
       "11_transformer_encoder.layers.1.Linear_linear1     614400.0  \n",
       "12_transformer_encoder.layers.1.Dropout_dropout         NaN  \n",
       "13_transformer_encoder.layers.1.Linear_linear2     614400.0  \n",
       "14_transformer_encoder.layers.1.Dropout_dropout2        NaN  \n",
       "15_transformer_encoder.layers.1.LayerNorm_norm2       300.0  \n",
       "16_transformer_encoder.layers.2.Dropout_dropout1        NaN  \n",
       "17_transformer_encoder.layers.2.LayerNorm_norm1       300.0  \n",
       "18_transformer_encoder.layers.2.Linear_linear1     614400.0  \n",
       "19_transformer_encoder.layers.2.Dropout_dropout         NaN  \n",
       "20_transformer_encoder.layers.2.Linear_linear2     614400.0  \n",
       "21_transformer_encoder.layers.2.Dropout_dropout2        NaN  \n",
       "22_transformer_encoder.layers.2.LayerNorm_norm2       300.0  \n",
       "23_transformer_encoder.layers.3.Dropout_dropout1        NaN  \n",
       "24_transformer_encoder.layers.3.LayerNorm_norm1       300.0  \n",
       "25_transformer_encoder.layers.3.Linear_linear1     614400.0  \n",
       "26_transformer_encoder.layers.3.Dropout_dropout         NaN  \n",
       "27_transformer_encoder.layers.3.Linear_linear2     614400.0  \n",
       "28_transformer_encoder.layers.3.Dropout_dropout2        NaN  \n",
       "29_transformer_encoder.layers.3.LayerNorm_norm2       300.0  \n",
       "30_transformer_encoder.layers.4.Dropout_dropout1        NaN  \n",
       "31_transformer_encoder.layers.4.LayerNorm_norm1       300.0  \n",
       "32_transformer_encoder.layers.4.Linear_linear1     614400.0  \n",
       "33_transformer_encoder.layers.4.Dropout_dropout         NaN  \n",
       "34_transformer_encoder.layers.4.Linear_linear2     614400.0  \n",
       "35_transformer_encoder.layers.4.Dropout_dropout2        NaN  \n",
       "36_transformer_encoder.layers.4.LayerNorm_norm2       300.0  \n",
       "37_transformer_encoder.layers.5.Dropout_dropout1        NaN  \n",
       "38_transformer_encoder.layers.5.LayerNorm_norm1       300.0  \n",
       "39_transformer_encoder.layers.5.Linear_linear1     614400.0  \n",
       "40_transformer_encoder.layers.5.Dropout_dropout         NaN  \n",
       "41_transformer_encoder.layers.5.Linear_linear2     614400.0  \n",
       "42_transformer_encoder.layers.5.Dropout_dropout2        NaN  \n",
       "43_transformer_encoder.layers.5.LayerNorm_norm2       300.0  \n",
       "44_fc_out                                             900.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummaryX import summary\n",
    "summary(model, torch.zeros((20, 4)).long().cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    labels = labels.ravel()\n",
    "    mask = (labels >= 0)\n",
    "    outputs = np.argmax(outputs, axis=1)\n",
    "    return np.sum(outputs == labels)/float(np.sum(mask))\n",
    "metrics = {\n",
    "    'accuracy': accuracy,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "def train(model, optimizer, loss_fn, data_iterator, metrics, num_steps):\n",
    "    model.train()\n",
    "    summ = []\n",
    "    t = trange(num_steps)\n",
    "    for i in t:\n",
    "        train_batch, labels_batch = next(data_iterator)\n",
    "        output_batch = model(train_batch)\n",
    "        output_batch = output_batch.view(output_batch.shape[0]*output_batch.shape[1], output_batch.shape[2])\n",
    "        labels_batch = labels_batch.view(labels_batch.shape[0]*labels_batch.shape[1],)\n",
    "        loss = loss_fn(output_batch, labels_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 20 == 0:\n",
    "            output_batch = output_batch.data.cpu().numpy()\n",
    "            labels_batch = labels_batch.data.cpu().numpy()\n",
    "            summary_batch = {metric: metrics[metric](output_batch, labels_batch)\n",
    "                             for metric in metrics}\n",
    "            summary_batch['loss'] = loss.item()\n",
    "            summ.append(summary_batch)\n",
    "\n",
    "    metrics_mean = {metric: np.mean([x[metric]\n",
    "                                     for x in summ]) for metric in summ[0]}\n",
    "    metrics_string = \" ; \".join(\"{}: {:05.3f}\".format(k, v)\n",
    "                                for k, v in metrics_mean.items())\n",
    "    print(\"- Train metrics: \" + metrics_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loss_fn, data_iterator, metrics, num_steps):\n",
    "    model.eval()\n",
    "    summ = []\n",
    "    for _ in range(num_steps):\n",
    "        data_batch, labels_batch = next(data_iterator)\n",
    "        output_batch = model(data_batch)\n",
    "        output_batch = output_batch.view(output_batch.shape[0]*output_batch.shape[1], output_batch.shape[2])\n",
    "        labels_batch = labels_batch.view(labels_batch.shape[0]*labels_batch.shape[1],)\n",
    "        loss = loss_fn(output_batch, labels_batch)\n",
    "        output_batch = output_batch.data.cpu().numpy()\n",
    "        labels_batch = labels_batch.data.cpu().numpy()\n",
    "        summary_batch = {metric: metrics[metric](output_batch, labels_batch)\n",
    "                         for metric in metrics}\n",
    "        summary_batch['loss'] = loss.item()\n",
    "        summ.append(summary_batch)\n",
    "    metrics_mean = {metric:np.mean([x[metric] for x in summ]) for metric in summ[0]} \n",
    "    metrics_string = \" ; \".join(\"{}: {:05.3f}\".format(k, v) for k, v in metrics_mean.items())\n",
    "    print(\"- Eval metrics : \" + metrics_string)\n",
    "    return metrics_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is skewed. Compute class weights and pass it to cross entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.6360e-05, 2.9205e-05, 1.0491e-06], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "total_tags = 0\n",
    "for tag in count_tags:\n",
    "    total_tags += count_tags[tag]\n",
    "class_weights = [0 for _ in range(unique_tags)]\n",
    "for tag, idx in tag2idx.items():\n",
    "    class_weights[idx] = 1/count_tags[tag]\n",
    "class_weights = torch.FloatTensor(class_weights).cuda()\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, train_tokens, train_tags, val_tokens, val_tags, optimizer, metrics):\n",
    "    loss_fn = nn.CrossEntropyLoss(class_weights, ignore_index=-1, reduction='mean')\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch + 1, num_epochs))\n",
    "        num_steps = (len(train_tokens) + 1) // batch_size\n",
    "        train_data_iterator = data_iterator(train_tokens, train_tags, batch_size, shuffle=True)\n",
    "        train(model, optimizer, loss_fn, train_data_iterator, metrics, num_steps)\n",
    "        num_steps = (len(val_tokens) + 1) // batch_size\n",
    "        val_data_iterator = data_iterator(val_tokens, val_tags, batch_size, shuffle=False)\n",
    "        val_metrics = evaluate(model, loss_fn, val_data_iterator, metrics, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/711 [00:00<00:27, 25.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 711/711 [00:29<00:00, 23.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Train metrics: accuracy: 0.977 ; loss: 0.038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/711 [00:00<00:25, 27.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Eval metrics : accuracy: 0.960 ; loss: 0.651\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 711/711 [00:29<00:00, 23.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Train metrics: accuracy: 0.977 ; loss: 0.038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/711 [00:00<00:25, 27.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Eval metrics : accuracy: 0.960 ; loss: 0.670\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 711/711 [00:29<00:00, 23.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Train metrics: accuracy: 0.978 ; loss: 0.036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/711 [00:00<00:25, 27.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Eval metrics : accuracy: 0.961 ; loss: 0.698\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 711/711 [00:29<00:00, 23.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Train metrics: accuracy: 0.978 ; loss: 0.036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/711 [00:00<00:25, 27.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Eval metrics : accuracy: 0.960 ; loss: 0.716\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 711/711 [00:29<00:00, 23.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Train metrics: accuracy: 0.978 ; loss: 0.036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/711 [00:00<00:25, 27.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Eval metrics : accuracy: 0.960 ; loss: 0.713\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 711/711 [00:29<00:00, 23.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Train metrics: accuracy: 0.978 ; loss: 0.036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/711 [00:00<00:25, 27.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Eval metrics : accuracy: 0.960 ; loss: 0.734\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 711/711 [00:29<00:00, 23.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Train metrics: accuracy: 0.978 ; loss: 0.036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/711 [00:00<00:25, 27.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Eval metrics : accuracy: 0.960 ; loss: 0.738\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 711/711 [00:29<00:00, 23.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Train metrics: accuracy: 0.978 ; loss: 0.035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/711 [00:00<00:25, 27.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Eval metrics : accuracy: 0.960 ; loss: 0.758\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 711/711 [00:29<00:00, 23.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Train metrics: accuracy: 0.978 ; loss: 0.035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/711 [00:00<00:25, 27.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Eval metrics : accuracy: 0.960 ; loss: 0.757\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 711/711 [00:29<00:00, 23.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Train metrics: accuracy: 0.977 ; loss: 0.036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/711 [00:00<00:27, 25.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Eval metrics : accuracy: 0.961 ; loss: 0.737\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 711/711 [00:29<00:00, 23.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Train metrics: accuracy: 0.977 ; loss: 0.036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/711 [00:00<00:25, 27.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Eval metrics : accuracy: 0.960 ; loss: 0.723\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 711/711 [00:29<00:00, 23.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Train metrics: accuracy: 0.976 ; loss: 0.043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/711 [00:00<00:25, 27.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Eval metrics : accuracy: 0.959 ; loss: 0.644\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 711/711 [00:29<00:00, 23.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Train metrics: accuracy: 0.972 ; loss: 0.053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/711 [00:00<00:25, 28.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Eval metrics : accuracy: 0.958 ; loss: 0.557\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 711/711 [00:29<00:00, 23.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Train metrics: accuracy: 0.971 ; loss: 0.053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/711 [00:00<00:25, 27.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Eval metrics : accuracy: 0.958 ; loss: 0.544\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 711/711 [00:29<00:00, 23.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Train metrics: accuracy: 0.973 ; loss: 0.048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/711 [00:00<00:25, 27.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Eval metrics : accuracy: 0.959 ; loss: 0.555\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 711/711 [00:29<00:00, 23.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Train metrics: accuracy: 0.975 ; loss: 0.043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/711 [00:00<00:25, 27.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Eval metrics : accuracy: 0.959 ; loss: 0.613\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 711/711 [00:29<00:00, 23.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Train metrics: accuracy: 0.977 ; loss: 0.038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/711 [00:00<00:25, 27.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Eval metrics : accuracy: 0.960 ; loss: 0.645\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 711/711 [00:29<00:00, 23.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Train metrics: accuracy: 0.977 ; loss: 0.035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/711 [00:00<00:25, 27.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Eval metrics : accuracy: 0.961 ; loss: 0.700\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 711/711 [00:29<00:00, 23.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Train metrics: accuracy: 0.978 ; loss: 0.034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/711 [00:00<00:25, 27.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Eval metrics : accuracy: 0.962 ; loss: 0.711\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 711/711 [00:29<00:00, 23.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Train metrics: accuracy: 0.979 ; loss: 0.034\n",
      "- Eval metrics : accuracy: 0.961 ; loss: 0.717\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate(model, train_tokens, train_tags, val_tokens, val_tags, optimizer, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=./model_100.pth>Download model file</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "def create_download_link(title = \"Download model file\", filename = \"./images.zip\"):  \n",
    "    html = '<a href={filename}>{title}</a>'\n",
    "    html = html.format(title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "\n",
    "torch.save(model.state_dict(), \"model_100.pth\")\n",
    "create_download_link(filename='./model_100.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Confidence Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_conf_mat(model, tokens, tags):\n",
    "    model.eval()\n",
    "    summ = []\n",
    "    conf_mat = np.zeros((unique_tags, unique_tags))\n",
    "    print(\"unique_tags\",unique_tags, conf_mat.shape)\n",
    "    for idx in trange(len(tokens)):\n",
    "        data = [tokens[idx]]\n",
    "        labels = tags[idx]\n",
    "        data = torch.LongTensor(data)\n",
    "        data = data.transpose(0, 1).contiguous().cuda()\n",
    "        outputs = model(data)\n",
    "        outputs = outputs.view(outputs.shape[0]*outputs.shape[1], outputs.shape[2])\n",
    "        outputs = outputs.data.cpu().numpy()\n",
    "        outputs = np.argmax(outputs, axis=1)\n",
    "        for i, j in  zip(labels, outputs):\n",
    "            conf_mat[i][j]+=1\n",
    "            \n",
    "    df_cm = pd.DataFrame(conf_mat, index = list(tag2idx.keys()), columns = list(tag2idx.keys()))\n",
    "    plt.figure(figsize = (10,7))\n",
    "    sn.heatmap(df_cm, annot=True)\n",
    "    \n",
    "    for i in range(unique_tags):\n",
    "        print()\n",
    "        print(idx2tag[i].upper())\n",
    "        print(\"precision\", conf_mat[i][i]/np.sum(conf_mat.T[i]))\n",
    "        print(\"recall\", conf_mat[i][i]/np.sum(conf_mat[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 16/2398 [00:00<00:14, 158.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique_tags 3 (3, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2398/2398 [00:15<00:00, 155.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GPE\n",
      "precision 0.71836398572605\n",
      "recall 0.8677055702917772\n",
      "\n",
      "PER\n",
      "precision 0.7497267759562841\n",
      "recall 0.8270042194092827\n",
      "\n",
      "O\n",
      "precision 0.9879965219604266\n",
      "recall 0.9715542950094889\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAGbCAYAAAAx9RHcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAvrElEQVR4nO3debyXY/748dfVOSWiRdYWYmTLkgpRiWiRslRjF1kahhnbMIxtGmaEsQ9fQiMxyZ4o7ZLSLlukxsxQiZCKouVcvz/Op/M7afvQWbr6vJ7zuB99Ptd9fe77uqePzvu839d13yHGiCRJUqoqlPcAJEmSNobBjCRJSprBjCRJSprBjCRJSprBjCRJSlp+aZ9gx2p7u1xKJerrpYvLewjazITyHoA2O8uXzSnTr9Xyrz4psZ+1FbfbPbn/JMzMSJKkpJV6ZkaSJJWygpXlPYJyZTAjSVLqYkF5j6BcWWaSJElJMzMjSVLqCnI7M2MwI0lS4qJlJkmSpHSZmZEkKXWWmSRJUtIsM0mSJKXLzIwkSanzpnmSJClplpkkSZLSZWZGkqTUuZpJkiSlzJvmSZIkJczMjCRJqbPMJEmSkmaZSZIkKV1mZiRJSp03zZMkSUmzzCRJkpQuMzOSJKXO1UySJClplpkkSZLSZWZGkqTUWWaSJEkpizG3l2ZbZpIkSUkzMyNJUupyfAKwwYwkSalzzowkSUpajmdmnDMjSZKSZmZGkqTU+aBJSZKUNMtMkiRJ6TIzI0lS6lzNJEmSkmaZSZIkKV1mZiRJSp1lJkmSlLQcD2YsM0mSpKSZmZEkKXExetM8SZKUMstMkiRJ6TIzI0lS6nL8PjMGM5Ikpc4ykyRJUrrMzEiSlDrLTJIkKWmWmSRJktJlMCNJUupiQcltWQgh5IUQ3g4hvJJ5v1sIYUIIYVYIoX8IoVKmfYvM+1mZ/fWKHePaTPuMEELbYu3tMm2zQgjXZDMegxlJklJXUFByW3YuBT4s9v424O4Y4x7AAuC8TPt5wIJM+92ZfoQQ9gVOBRoA7YAHMwFSHvAAcCywL3Bapu96GcxIkqSshRDqAMcBj2beB6AV8FymSx/gxMzrEzLvyew/OtP/BODpGOOPMcb/ALOAQzLbrBjjJzHGZcDTmb7rZTAjSVLqSjAzE0LoHkKYXGzr/pOz3QNcDaxK49QEvo0xrsi8nw3UzryuDXwGkNm/MNO/qP0nn1lX+3q5mkmSpNSV4NLsGGMvoNfa9oUQOgBfxhinhBCOLLGTbiSDGUmSlK1mwPEhhPZAZaAqcC9QPYSQn8m+1AHmZPrPAeoCs0MI+UA14Oti7asU/8y62tfJMpMkSakrownAMcZrY4x1Yoz1KJzAOzLGeAYwCuiS6XY2MCDz+uXMezL7R8YYY6b91Mxqp92A+sBEYBJQP7M6qlLmHC9v6PLNzEiSlLryvwPwH4GnQwi3AG8Dj2XaHwP6hhBmAd9QGJwQY/wghPAMMB1YAVwcY1wJEEK4BBgC5AG9Y4wfbOjkoTBAKj07Vtu7dE+gnPP10sXlPQRtZkJ5D0CbneXL5pTp12rpgNtL7Gftlidcndx/EpaZfqFatXfihYF9eGPCK4weP5ALLjxrrf0Ob34II8a8yOjxA3nx1b4bfd5KlSrS6593Mf7tIQwe0Z+6uxRO8j6o0f6MGPMiI8a8yMg3X+LYDsds9LmUlmrVqtL/6V68/95o3nv3dZoe2pjbbr2e998bzdQpw3ju2UepVq1qeQ9TZWSLLbZg3NhXmDJ5GNOmjeTGG69cZ9+TTmrP8mVzaNzogI0+b716dRn75kA+nP4mTz31f1SsWBGAyy7tzjvvjGLqlGEMea0/u+yywQUq+jnK/j4zmxSDmV9oxYqV3HT9bRxxaAfaH3Mq3S44gz33+tVqfapW24aed95I19N+S8umHbng7EuzPn7dXWrzwitPrNF+etcufPvtIpoe1JaHH+zDDT0K/4H66MOZtDmyC0e3OIlTO1/A3+/pQV5e3sZdpJJy911/YciQUey3f0saNW7Nhx/NZPiINziwYSsaNW7NzJmfcM0fLynvYaqM/Pjjj7RuczKNm7SmSZM2tG1zJIce0miNfltvXYXfXXIeEyZM/VnH73rWydxwwxVrtP/tb9dx732PsM++zfl2wULO7XYaAG9Pe5+mTY+lUePWvPDCq9x66/W/7MK0dmV8B+BNTdbBTAhhyxDCXqU5mJR8+cV83ntnOgDff/c9M2f8m51q7bhan06/7sCggcOYM/tzAL766puifZ1P7shrI59hxJgXueOeHlSokN1fRbv2R/PMv14CYOBLQ2je8jAAli79gZUrVwJQuXIlSrt8qE1L1arb0KL5ofT+Zz8Ali9fzsKFixg2/I2i78X4CVOpXXvn8hymytj33y8BoGLFfCpWrLjWfxd6/Plq7vj7g/zwww9FbRUqVKDnrdfz1rhXmTplGBecf2bW5zzqyGY8//yrAPTt+yzHH194l/rRo8exdGnhOSZMnEIdv4sqQVn9BA0hdASmAa9l3jcMIWxwdnGuqLtLbfY7YB+mTn5ntfZf/aoe1apX5YVXnmDo6Of59amFNzGsv+funNipPR3anM7RLU5i5cqVdD65Y1bn2nnnHZgzpzA4WrlyJYsXLWbbbasD0KjxAYweP5DXx73MVZf/ueiHmDZ/u+22C1999TWPPXo3kyYO4eGH7mCrrbZcrU+3c07ltSGjymmEKg8VKlRg8qShzJ3zLsNHvMHESW+vtv+ghvtRp+7ODB48YrX2c7udxsJFizns8ONoethxnHfe6dSrV5cNqVmzBt9+u7Do357Zcz6nVu2d1ujX7ZzT/C6WtBwvM2W7munPFN5i+HWAGOO0zFKqtcrcLbA7wDaVd2TLStU3apCbsq2qbMVjfe/jhmtv5bvF36+2Ly8/nwMbNqDL8d2oXHkLXh3+NFMmvUOLlodxQMMGDBn1LACVt6zMV/MLszb/fPJ+dtm1DhUrVaROnZ0ZMeZFAB55qC9PP/XCescydcq7tGzakfp77s79D/Vk5LA3+PHHZaVw1drU5OflcdBB+3PpZTcwcdLb3HVnD/549SXc9Oc7ALj2mt+zYsUK/vWv9X+HtHkpKCigycFtqFatKs89+xgNGuzFBx/MACCEwB133MR551++xueOad2S/fffh86djgMKM3977LEbixZ9x9Ah/QGoUaM6lSpV5ITj2wFwTrff8/nnX2xwTKef3onGjQ+k1dGdS+oyBckGISUl22BmeYxxYeHjFIqss45R/O6Bm/Nqpvz8fHr3vY/nnxnIoIHD1tj/+dx5LPjmW5YsWcqSJUsZP24yDfbfixACz/R7ib/2uGuNz3Q783dAYbbn3gdvpVOHrqsf8/MvqV17Zz6f+wV5eXlsU3Ubvvnm29X6zPz4E77/fgl777sn77z9fsldsDZZs+d8zuzZnxf95v3CC69y9VWF82O6nnUyx7U/htZtTy7PIaocLVy4iNdHj6VNmyOLgpltttmaBg32Zviwwsfp7LTT9rzwwj/p1KkbIcBll13PsGGj1zhWk4PbAIXfq13r1eHmm1f/d6x69Wrk5eWxcuVK6tTemblz5hXta9WqBddc83uOProzy5b5i5ZKTrZzZj4IIZwO5IUQ6ocQ7gfGleK4knD3P25h5ox/8/ADj691/2uvjuDQwxqRl5fHlltWplHjA5g54xPGjH6LDie0YbvttgWgeo1q1KlbK6tzDhk0kpNPPxGAjie25c03xgOwy661iyb81qlbiz3q785n/5u9cReoZHzxxXxmz57LnnsWTkJv1ao5H374MW3bHMkf/nARJ3Y6p2i+gnLDdtttW7R6rXLlyhxz9BHMmPHvov2LFi1m51r7U3/PptTfsykTJkylU6duTJn6LsOGjuY3v+lKfn7h77v16+++RtlyXV4fPY7OnQszOmed9WsGDhwKQMOGDXjwgZ506tSN+fO/LslLFUCMJbclKNvMzO+A64AfgX4U3szm5tIaVAoOadqIk087kenvzygqBf3tL3dTu27hpLYnevdn5sefMHL4GEaNG0AsKOCpJ57jow9nAtDzlnvp/+JjVKhQgeUrVnDtlX9h9mdzN3jef/V9jn/0up3xbw/h2wUL+c25V2TG05jfXX4BK5avoCAWcM2VPdbI2GjzdunlN/BEn/upVKki//nPp5x3/hWMH/cqW2yxBa8NfhqACROmcvEl15TzSFUWdt55R3o/dg95eRUIFSrw3HMDGTRoODfd9AemTHmHV15ZM5u8ymO9/8Wu9eoyaeJrEAJfzf+Gzl3Ozeq8f/rTX3nqyQfp8eermfbOB0WT0nveegNbb12Fp/s9DMCnn82hU6duG3+hKpTjZaafddO8EEJVIMYYs75r2eZcZlL58KZ5KmnJ3SFMm7wyv2lev5tK7qZ5p/VI7j+JrDIzIYSDgd7ANpn3C4FzY4xTSnFskiQpGzmemcm2zPQY8NsY4xiAEEJz4J/Axt8uUpIkbZxEb3ZXUrKdALxyVSADEGN8k8IHQ0mSJJWrbDMzo0MID1M4+TcCpwCvhxAaAcQYf959sCVJUsmxzJSVAzN/3pj5c9XkoIMoDG5aleSgJEnSz5DokuqSkm0w8wqFQcuqICYCC4EpMcZppTAuSZKkrGQbzDQGmgAvUxjQdADeBX4TQnguxnh7KY1PkiRtiGWmrNQBGsUYvwMIIdwEvAq0BKYABjOSJJWXHA9msl3NtAOFd/9dZTmwY4xx6U/aJUmSylS2mZmngAkhhAGZ9x2Bf4UQqgDTS2VkkiQpOzl+n5msgpkY480hhMFAs0zThTHGyZnXZ5TKyCRJUlZigauZspIJXiZvsKMkSVIZyjqYkSRJm6gcnwBsMCNJUupyfM5MtquZJEmSNklmZiRJSp0TgCVJUtKcMyNJkpKW48GMc2YkSVLSzMxIkpS66JwZSZKUMstMkiRJ6TIzI0lS6lyaLUmSkuYdgCVJktJlZkaSpNRZZpIkSSmLrmaSJElKl5kZSZJSZ5lJkiQlzdVMkiRJ6TIzI0lS6iwzSZKkpLmaSZIkKV1mZiRJSp1lJkmSlDRXM0mSJKXLzIwkSamzzCRJklLms5kkSZISZmZGkqTUWWaSJElJy/FgxjKTJElKmpkZSZJSl+P3mTGYkSQpdZaZJEmS0mVmRpKkxMUcz8wYzEiSlLocD2YsM0mSpKSZmZEkKXU5/jgDgxlJklJnmUmSJCldZmYkSUpdjmdmDGYkSUpcjLkdzFhmkiRJSTMzI0lS6iwzSZKkpOV4MGOZSZIkJa3UMzNfL11c2qdQjqmcX6m8h6DNzA8rlpX3EKSN4rOZJElS2nI8mLHMJEmSkmZmRpKk1OX2o5kMZiRJSl2uz5mxzCRJkpJmMCNJUuoKYslt6xFCqBxCmBhCeCeE8EEIoUemfbcQwoQQwqwQQv8QQqVM+xaZ97My++sVO9a1mfYZIYS2xdrbZdpmhRCuyebyDWYkSUpdQQlu6/cj0CrGeCDQEGgXQmgK3AbcHWPcA1gAnJfpfx6wINN+d6YfIYR9gVOBBkA74MEQQl4IIQ94ADgW2Bc4LdN3vQxmJElSVmKh7zJvK2a2CLQCnsu09wFOzLw+IfOezP6jQwgh0/50jPHHGON/gFnAIZltVozxkxjjMuDpTN/1MpiRJClxsSCW2BZC6B5CmFxs6178XJkMyjTgS2AY8G/g2xjjikyX2UDtzOvawGcAmf0LgZrF23/ymXW1r5ermSRJSl0JLs2OMfYCeq1n/0qgYQihOvAisHfJnf2XMTMjSZJ+thjjt8Ao4DCgeghhVYKkDjAn83oOUBcgs78a8HXx9p98Zl3t62UwI0lS4kqyzLQ+IYTtMxkZQghbAq2BDykMarpkup0NDMi8fjnznsz+kTHGmGk/NbPaaTegPjARmATUz6yOqkThJOGXN3T9lpkkSUpd2d0BeGegT2bVUQXgmRjjKyGE6cDTIYRbgLeBxzL9HwP6hhBmAd9QGJwQY/wghPAMMB1YAVycKV8RQrgEGALkAb1jjB9saFChMEAqPfmVauf2bQlV4nxqtkqaT81WSVuxbE4oy/N93bFlif2srTlwdJmOvSRYZpIkSUmzzCRJUup80KQkSUpZzPFgxjKTJElKmpkZSZJSl+OZGYMZSZISZ5lJkiQpYWZmJElKXK5nZgxmJElKXK4HM5aZJElS0szMSJKUupjcEwhKlMGMJEmJs8wkSZKUMDMzkiQlLhZYZpIkSQmzzCRJkpQwMzOSJCUuuppJkiSlzDKTJElSwszMSJKUOFczSZKkpMVY3iMoX5aZJElS0szMSJKUOMtMkiQpabkezFhmkiRJSTMzI0lS4nJ9ArDBjCRJibPMJEmSlDAzM5IkJc5nM0mSpKT5bCZJkqSEmZmRJClxBZaZJElSynJ9zoxlJkmSlDQzM5IkJS7X7zNjMCNJUuJy/Q7AlpkkSVLSzMxIkpQ4y0ySJClpub402zKTJElKmpkZSZISl+v3mTGYkSQpca5mkiRJSpiZGUmSEucEYJWLWR+P5+2pw5k8aSjj3xoEwIEHNmDsmIFFbQc3aVi+g1SZevCh2/jPfycxcdJr6+3XqPEBfLtoJieeeOxGn7NGjWq8PLAv094dycsD+1K9elUAjuvQmvETBjNu/Ku88eYADjusyUafS2WrTp1aDB/6LO++M4p3po3kd5ect0afjh3bMHXKsKJ/c5odfvBGn7dGjeq8NqgfH37wJq8N6kf16tUAOO20k5g6ZRhvTx3OmNEDOOCAfTf6XPr/YgwltqXIYKYcHdP61zQ5uA1ND2sPQM+/XcfNt9xFk4Pb0KPH3+l563XlPEKVpaf6Ps+JJ56z3j4VKlTg5pv/yIgRY37WsVu0OJSHHr5jjfYrrryI118fS8MDWvH662O54sqLAHh91FiaHnoshzc9josu/CMPPNjzZ51P5W/FihVcdXUPDjjwKJo178hFF53DPvvUX63PyJFv0qhxa5oc3IYLul/Jww//PevjtzziMB579O412v949cWMHPUm+zRozshRb/LHqy8G4L//+YxWR3fhoEbH8Ne/3cNDD962cRcoFWMwswmJMbJN1W0AqFptG+Z+/kU5j0hlaezYiSz45tv19rnworMZMOA15n/59Wrtl17WndFjXmL8hMFcd/1lWZ/zuA6teeqp5wF46qnn6dCxDQDff7+kqE+VrbYk5vrswgTNm/clb097H4Dvvvuejz6aSe1aO63WZ/W/561W+3u+8ooLeWvcq0ydMoybbrwy6/N27NiWJ/o+C8ATfZ/l+OPbAfDW+Ml8++1CAMZPmErt2jv/sgvTWsVYcluKNhjMhBDyQgiXl8VgckmMkcGD+jFh/GDOP+8MAK74w03cduv1/Offk7i95w1cd/2t5TxKbUp2rrUjxx/flkd6Pblae6ujW7DHHvVo2eJEDmvanoYH7UezZodkdcwddtiOL+bNB+CLefPZYYftivZ1PL4NU98eznMv9OaiC68uuQtRmdt11zo0PHA/Jkx8e419J5zQjvffG83LA/pwwQWFQUvrY45gjz1247DDj6NxkzY0OugAWjQ/NKtz7bjDdsyb9yVQGFDtWOw7tcq53U7ltSGjNuKK9FMFMZTYlqINTgCOMa4MIZwGrJlP1C/W8qiTmDt3HttvX5PXBj/NjBmz6NTpOK686s+8+OIgunTpyCMP30nbY08t76FqE3H77Tdyw/U918iSHH10C1od3YJx418FoEqVrfjVHvUYO3Yio0a/yBZbVKJKla2oUaN6UZ8brr+NEcPfWOMcxY898OWhDHx5KM2aHcINN15Bxw5nleLVqbRUqbIVz/R/hCv+cBOLF3+3xv4BA15jwIDXaNH8UHr8+SraHnsqrY9pSetjWjJ50lAAtq6yFXvssRtj3pzAuDcHUmmLLdi6ylZsu231oj5/+tNfGTps9BrH/+n39ciWh9Ot22m0PPKkUrha5apsVzONDSH8A+gPfL+qMcY4dW2dQwjdge4AIa8aFSpU2dhxbnbmzp0HwPz5XzNgwGAOPrghXc/6NZdfcSMAzz03kF4PrTnHQbnroEb78/gT9wNQs2YN2rY9khUrVxBC4M6/P0jvx/qt8ZmjWhb+wGjR4lDOOLMLF/7mqtX2f/nlV+y40/Z8MW8+O+60PfPnf73GMcaOnUi93XahZs0afP31glK4MpWW/Px8nu3/CP36vchLLw1eb98xb05gt8zfcwiB227/B488+uQa/Q5v3hEonDPTtevJnHf+6on7L778ip122oF5875kp5124Mti36n999+Hhx+6gw7Hn8U33/hdKkmpTtwtKdnOmWkINAD+AtyZ2dY5UyzG2CvG2CTG2MRAZk1bbbUlW29dpeh162Na8sEHM5j7+Re0POIwAFod1ZyZs/5TnsPUJma/fY+gwT4taLBPC156cTCXX3YjrwwcxvDhb3BW15OpUmUroLActf32NbM65qBXh3PGGZ0BOOOMzrz6yjAAdt9916I+BzZswBZbVDKQSdAjve7kw49mcc+9vda6/1e/qlf0+qCG+xX9PQ8d9jrdzjml6DtVq9ZOWX+nXhk4lK5n/RqArmf9moEDhwBQt24tnu3/COd0u5SZMz/ZiKvS2lhmykKM8ajSHkgu2XHH7Xnu2ccAyM/P4+mnX2LI0Nf57sKruOuuv5Cfn8+PP/zARRc5TyGX/PPxe2lxRFNq1qzBjJnj+Ost91CxYuF/oo89+q91fm7kiDHsvdevGDmqcCLvd98v4fxzL19rluWn7rrz/3ii7z/oevbJfPbpHLqedQkAJ5zYjtNP78TyFStYuvQHzj7rdyVwhSpLzQ4/mLPO7MK7700vKgXdcENP6tatDUCvR/rS6aT2nHlmF5YvX8EPS3/g9DMKV7MNG/4Ge+9dnzfHvAzA998toes5v8vqO3XbHQ/w9L8eots5p/Hpp7M59fQLAbj+usupWbMG99//N6BwtdWqlZzSxgrZrFIIIewI/A2oFWM8NoSwL3BYjPGxDX02v1LtROdGa1NVOb9SeQ9Bm5kfViwr7yFoM7Ni2ZwyTXGMr9WpxH7WNp37QnLpmWzLTI8DQ4BamfcfA5eVwngkSdLPlOtlpmyDme1ijM8ABQAxxhXAylIblSRJypp3AM7O9yGEmkAECCE0BRaW2qgkSZKylO3S7CuAl4HdQwhjge2BLqU2KkmSlLWC8h5AOcs2mJkOvAgsARYDL1E4b0aSJJWzSJrloZKSbZnpCWBvClc03Q/sCfQtrUFJkiRlK9vMzH4xxuLPax8VQpheGgOSJEk/T0GO3wQl28zM1MykXwBCCIcCk0tnSJIk6ecoIJTYlqJsMzONgXEhhE8z73cBZoQQ3gNijPGAUhmdJEnSBmQbzLQr1VFIkqRfLNcnAGf7bKb/lfZAJEnSL5PrS7OznTMjSZK0Scq2zCRJkjZRlpkkSVLSLDNJkiQlzMyMJEmJy/XMjMGMJEmJy/U5M5aZJElS0szMSJKUuILcTswYzEiSlLpUn6lUUiwzSZKkrIQQ6oYQRoUQpocQPgghXJpp3zaEMCyEMDPzZ41Mewgh3BdCmBVCeDeE0KjYsc7O9J8ZQji7WHvjEMJ7mc/cF0LYYKRmMCNJUuJiCW4bsAK4Msa4L9AUuDiEsC9wDTAixlgfGJF5D3AsUD+zdQf+DwqDH+Am4FDgEOCmVQFQps8FxT63wedDGsxIkpS4ghLc1ifG+HmMcWrm9WLgQ6A2cALQJ9OtD3Bi5vUJwBOx0HigeghhZ6AtMCzG+E2McQEwDGiX2Vc1xjg+xhiBJ4oda50MZiRJUpEQQvcQwuRiW/d19KsHHARMAHaMMX6e2TUP2DHzujbwWbGPzc60ra999lra18sJwJIkJa5gw9NKshZj7AX0Wl+fEMLWwPPAZTHGRcWntcQYYwghi4pVyTEzI0lS4spwzgwhhIoUBjJPxRhfyDR/kSkRkfnzy0z7HKBusY/XybStr73OWtrXy2BGkiRlJbOy6DHgwxjjXcV2vQysWpF0NjCgWHvXzKqmpsDCTDlqCNAmhFAjM/G3DTAks29RCKFp5lxdix1rnSwzSZKUuDJ8NlMz4CzgvRDCtEzbn4CewDMhhPOA/wEnZ/YNAtoDs4AlQDeAGOM3IYSbgUmZfn+JMX6Tef1b4HFgS2BwZluvUDhZuPTkV6pdpnUzbf4q51cq7yFoM/PDimXlPQRtZlYsm1Omd7HrV+uMEvtZe9rcp5K7A59lJkmSlDTLTJIkJS7XH2dgMCNJUuJyfT6HZSZJkpQ0MzOSJCWuILerTAYzkiSlrgyXZm+SLDNJkqSkmZmRJClxuT4B2GBGkqTE5fqcGctMkiQpaWZmJElKXK5PADaYkSQpcbkezFhmkiRJSTMzI0lS4mKOTwA2mJEkKXGWmSRJkhJmZkaSpMTlembGYEaSpMTl+h2ALTNJkqSkmZmRJClxuf44A4MZSZISl+tzZiwzSZKkpJmZkSQpcbmemTGYkSQpca5mkiRJSpiZGUmSEudqJkmSlDTnzEiSpKQ5Z0aSJClhZmYkSUpcQY7nZko9mKmYZ7ykkvXjimXlPQRtZpbOHVPeQ5A2Sq7PmbHMJEmSkmbaRJKkxOV2kclgRpKk5FlmkiRJSpiZGUmSEucdgCVJUtJyfWm2ZSZJkpQ0MzOSJCUut/MyBjOSJCXP1UySJEkJMzMjSVLicn0CsMGMJEmJy+1QxjKTJElKnJkZSZISl+sTgA1mJElKXK7PmbHMJEmSkmZmRpKkxOV2XsZgRpKk5OX6nBnLTJIkKWlmZiRJSlzM8UKTwYwkSYmzzCRJkpQwMzOSJCUu1+8zYzAjSVLicjuUscwkSZISZ2ZGkqTEWWaSJElJczWTJElSwszMSJKUOG+aJ0mSkmaZSZIkKWFmZiRJSpxlJkmSlDTLTJIkSQkzMyNJUuIKomUmSZKUsNwOZSwzSZKkxJmZkSQpcT6bSZIkJS3Xl2ZbZpIkSUkzMyNJUuK8z4wkSUpaAbHEtg0JIfQOIXwZQni/WNu2IYRhIYSZmT9rZNpDCOG+EMKsEMK7IYRGxT5zdqb/zBDC2cXaG4cQ3st85r4QQtjQmAxmJEnSz/E40O4nbdcAI2KM9YERmfcAxwL1M1t34P+gMPgBbgIOBQ4BbloVAGX6XFDscz891xoMZiRJSlwswf9t8FwxvgF885PmE4A+mdd9gBOLtT8RC40HqocQdgbaAsNijN/EGBcAw4B2mX1VY4zjY4wReKLYsdbJYEaSpMQVlOAWQugeQphcbOuexRB2jDF+nnk9D9gx87o28FmxfrMzbetrn72W9vVyArAkSSoSY+wF9NqIz8cQQpmuFTczI0lS4mKMJbb9Ql9kSkRk/vwy0z4HqFusX51M2/ra66ylfb0MZiRJSlxZrmZah5eBVSuSzgYGFGvvmlnV1BRYmClHDQHahBBqZCb+tgGGZPYtCiE0zaxi6lrsWOtkmUmSJGUthNAPOBLYLoQwm8JVST2BZ0II5wH/A07OdB8EtAdmAUuAbgAxxm9CCDcDkzL9/hJjXDWp+LcUrpjaEhic2dbLYEaSpMSV5U3zYoynrWPX0WvpG4GL13Gc3kDvtbRPBvb7OWMymJEkKXG5/mwmgxlJkhKX60/NdgKwJElKmpkZSZIStxFLqjcLBjOSJCXOp2ZLkiQlzMyMJEmJczWTJElKmquZ9ItdfHE3Jk8eypQpw7jkknPX2H/55b9h/PhBjB8/iMmTh/Ldd59Qo0a1jTpnpUqV6Nv3H7z//mjeeOMldtml8BEWrVo1Z+zYV5g0aQhjx75Cy5aHb9R5tOmoUKECkyYO4aUX+2z0sa6++hI+nP4m77//Bq1btwSgTp1aDBv6LO+8M4pp00byu0vO2+jzaNOxcuVKupxzMb+96qY19t1278N0PvtiOp99Mcedej6Hte2y0edbuGgx51/6J9qfch7nX/onFi5avNr+9z6cwYFHHMfQUWM2+lzSKgYzv9C+++5Jt26n0aLF8RxySDuOPfZodt9919X63H33wzRt2p6mTdtz4423MWbMBBYsWJjV8XfZpQ5Dhjy9Rvs555zCggUL2W+/ltx//2P89a/XAPD11wvo0uVcDj64LRdccAW9e9+98RepTcLvf3c+H34082d9ZubH49do22ef+pxy8gkc2LAVHTqcwf33/Y0KFSqwYsUKrr66BwceeBTNm3fkwovOYZ996pfU8FXOnnx2ALvX22Wt+/546W94vs8DPN/nAU7v3JGjf8YvQROnvst1t9y5RvujfZ+haZOGDOr/GE2bNOSxJ58p2rdy5UrufvCfHH5wo59/IVqvTeBBk+Uqq2AmhFA5hLBfZqtc2oNKwd5778GkSdNYuvQHVq5cyZgxEzjxxHbr7H/yySfwzDP//1lZp556EmPGDGD8+EHcf3/hD5VsdOjQmqeeeh6AF14YxJFHNgPgnXc+4PPPCx9SOn36x1SuXJlKlSr90svTJqJ27Z059tij6d27X1Fbo4P2Z8Tw55gwfjCvvvIUO+20Q1bH6tixLf2fGcCyZcv4738/49///i+HHHwQ8+Z9ydvT3gfgu+++56OPZlKr1k6lcj0qW/O+nM8b4ybSuWPbDfYdNHw07Y85suh976ee45Tzfs9JXS/iH4/2zfqco8a8xQnHHgPACccew8g33ira96/nXqb1kc3Ytkb1rI+n7GwCD5osV+v9CRpCyA8h3A7MBvoATwCfhRBuDyFULIsBbqo++OBjmjU7mG23rc6WW1amXbujqFOn1lr7brllZVq3bslLLxU+K2uvvfagS5cOHHVUZ5o2bc/KlQWceuqJWZ23Vq2dmD17LlD4W86iRYupWbPGan1OOqk906a9z7Jly375BWqTcOedPbj22lsoKChceJmfn88999zCKad259Cmx/J4n/7c/Jc/ZnWs2sW+OwBz5nxOrdqrBy277lqHhgfux8SJb5fcRajc3Hbvw1zx2/MIYf2/LM2d9wVzPp/HoY0PBGDshCl8OnsOTz96L88//gDTZ8xi8rT3sjrn1wu+ZfvttgVgu5o1+HrBtwB8Mf8rRrwxjlNOOu6XX5C0DhuaAHwHsA2wW4xxMUAIoSrw98x26do+FELoDnQHyM/flvz8rUtswJuKGTNmceedDzFw4JMsWbKEd975gJUrV66173HHHcNbb00uKjEddVQzGjXanzfffBkoDHbmz/8KgP79H2bXXetSqVIl6tatxfjxgwB44IF/0rfvsxsc1z771OeWW66hQ4czS+IyVY7atz+G+V9+xdS33+OIIw4DYK+9fkWDBnvx2uDCEmReXoWijNw11/yeLp07AFCr1o5MnjQUgHHjJvH7S6/b4PmqVNmKZ/o/wpV/uInFi78rjUtSGXp97AS2rVGdBnvXZ+LUd9fbd/Dw0bQ5sjl5eXkAjJs0lXETp9LlnEsAWLJ0Kf/7bC5NGu7PaRdcxrJly1mydCkLFy2m89mFzxC84rfn0uzQxqsdN4RACAEoDKwuv+jcrLPQ+nlczbR+HYA9Y7EiWoxxUQjhIuAj1hHMxBh7Ab0Attxy1832/+E+ffrTp09/AHr0uIo5c+attd+vf92RZ599ueh9CIEnn3yOG2+8fY2+p5zyG6Bwzswjj/ydtm1PXW3/3LnzqFOnFnPmzCMvL4+qVbfh668XAFC79k7079+L88+/gv/859MSuUaVn8MPb0KHDm1o164VlStvQdWq23DjjVcyffrHtDji+DX69+x5Hz173gcUzplpcnCb1fbPyXx3Vqlde2fmZr6z+fn5PNP/Efr1e7Eog6i0vf3udF5/czxj3prEj8uW8/33S/hjj9u57aar1+g7ePhorruy2IONI5x/1imcfGL7Nfr2e+QeoHDOzIBBw/jr9Veutr9mjerM/+obtt9uW+Z/9Q3bVi9c9PDBRzO56qaeACxYuIgxb00iLy+Po49wsUJJKEh0rktJ2VCIHONaZgPFGFdCjoeBwPbb1wSgbt1anHBCO/r3H7BGn6pVt6F586YMHDi0qG3UqLGcdFL7os/XqFGNXXapndU5X311OGec0RmATp3aM3r0OACqVavKCy/8kxtuuI233pq8UdelTcP11/dkt92bUH/Pppxx5m8ZNWosZ555Mdttty1NM78B5+fns+++e2Z1vFdeGcopJ59ApUqVqFevLnvssRsTJxWWkx7pdScffTSLe+7tVWrXo7J1+UXdGPHSkwx9vg939LiGQxofuNZA5pP/fcaixd/RcL99itoOP6QRL746lCVLlgKFJaJV5aINObJ5UwYMHg7AgMHDOapFYVZxyHOPM/T5Pgx9vg9tjmzO9X+42EBGJWZDmZnpIYSuMcYnijeGEM6kMDOT0/r1e4htt63B8uXLueyyG1m4cBHnn38GAI8++hQAxx/flhEj3ij6RwHgo49m0qPH3xk4sC8VKlRg+fIVXH75DXz66ZwNnvPxx/vTu/fdvP/+aBYs+JazzipMA1944dn86lf1uPba33Pttb8HoGPHs5g//+uSvmyVo+XLl3Pqab/h7rv+QrVqVcnLz+P++x5l+vSPN/jZ6dM/5tnnBvLuO6NYsXIlv7/0OgoKCmh2+MGceWYX3ntvelFp6vobevLaayNL+3JUDv7xyBM02HtPjmrRFCjMyhx7TMuichBAs0Mb88n/PuOM31wBwFZbVubWG6+iZhYTd88/62SuvOFvvPDKEGrttAN33vynUrkOrS7XswthfcuwQgi1gReApcCUTHMTYEvgpBjjBn/6bs5lJpWPFStXlPcQtJlZMtd7nqhkVdxu97DhXiWnWe1WJfazduyckWU69pKw3sxMJlg5NITQCmiQaR4UYxxR6iOTJEnKQlaPM4gxjgTMOUuStAlK9f4wJcVnM0mSlLhU79xbUlzwL0mSkmZmRpKkxFlmkiRJScv1OwBbZpIkSUkzMyNJUuJyfQKwwYwkSYnL9TkzlpkkSVLSzMxIkpQ4y0ySJClplpkkSZISZmZGkqTE5fp9ZgxmJElKXEGOz5mxzCRJkpJmZkaSpMRZZpIkSUmzzCRJkpQwMzOSJCXOMpMkSUqaZSZJkqSEmZmRJClxlpkkSVLSLDNJkiQlzMyMJEmJs8wkSZKSFmNBeQ+hXFlmkiRJSTMzI0lS4gosM0mSpJRFVzNJkiSly8yMJEmJs8wkSZKSZplJkiQpYWZmJElKXK4/zsBgRpKkxOX6HYAtM0mSpKSZmZEkKXG5PgHYYEaSpMS5NFuSJCUt1zMzzpmRJElJMzMjSVLiXJotSZKSZplJkiQpYWZmJElKnKuZJElS0iwzSZIkJczMjCRJiXM1kyRJSpoPmpQkSUqYmRlJkhJnmUmSJCXN1UySJEkJMzMjSVLicn0CsMGMJEmJs8wkSZKUMDMzkiQlLtczMwYzkiQlLrdDGctMkiQpcSHXU1ObkhBC9xhjr/IehzYPfp9U0vxOaVNlZmbT0r28B6DNit8nlTS/U9okGcxIkqSkGcxIkqSkGcxsWqxFqyT5fVJJ8zulTZITgCVJUtLMzEiSpKQZzEiSpKQZzEiS1iuEUCeEMCCEMDOE8O8Qwr0hhErlPS5pFYMZKUeFEHyciTYohBCAF4CXYoz1gT2BrYG/luvApGIMZspQCOGGEMKMEMKbIYR+IYQ/hBBez/yWMy2E8H4I4ZBM3yohhN4hhIkhhLdDCCeU9/i16Qkh1AshfBRCeCqE8GEI4bkQwlYhhMYhhNEhhCkhhCEhhJ0z/V8PIdwTQpgMXFrOw1caWgE/xBj/CRBjXAlcDpwbQtiqXEcmZRjMlJEQwsFAZ+BA4FigSbHdW8UYGwK/BXpn2q4DRsYYDwGOAu4IIVQpuxErIXsBD8YY9wEWARcD9wNdYoyNKfxOFf8tulKMsUmM8c6yH6oS1ACYUrwhxrgI+BTYo1xGJP2Eaeay0wwYEGP8AfghhDCw2L5+ADHGN0IIVUMI1YE2wPEhhD9k+lQGdgE+LMMxKw2fxRjHZl4/CfwJ2A8YVlghIA/4vFj//mU7PEkqXQYzm4af3uwnAgHoHGOcUQ7jUVp++v1ZDHwQYzxsHf2/L+XxaPMyHehSvCGEUJXCX65mlcuIpJ+wzFR2xgIdQwiVQwhbAx2K7TsFIITQHFgYY1wIDAF+l5l8RwjhoLIesJKxSwhhVeByOjAe2H5VWwihYgihQbmNTqkbAWwVQugKEELIA+4EHo8xLinXkUkZBjNlJMY4CXgZeBcYDLwHLMzs/iGE8DbwEHBepu1moCLwbgjhg8x7aW1mABeHED4EapCZLwPcFkJ4B5gGHF5+w1PKYuFt4k8Cfh1CmAl8DPxAYTlT2iT4OIMyFELYOsb4XWYFwBtAd+Au4A8xxsnlOzqlKIRQD3glxrhfeY9FksqLc2bKVq8Qwr4UTubtE2OcmqkiSZKkX8jMjCRJSppzZiRJUtIMZiRJUtIMZiRJUtIMZiRJUtIMZiRJUtL+H8x7DUy6NgaqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_conf_mat(model, val_tokens,val_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (encoder): Embedding(400002, 300)\n",
       "  (pos_encoder): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=300, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=300, bias=True)\n",
       "        (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=300, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=300, bias=True)\n",
       "        (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (2): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=300, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=300, bias=True)\n",
       "        (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (3): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=300, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=300, bias=True)\n",
       "        (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (4): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=300, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=300, bias=True)\n",
       "        (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (5): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=300, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=300, bias=True)\n",
       "        (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc_out): Linear(in_features=300, out_features=3, bias=True)\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"./model_100.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, sentence):\n",
    "    model.eval()\n",
    "    words = sentence.translate(str.maketrans('','',string.punctuation)).split()\n",
    "    data = [[word_to_index[word.lower()] for word in words]]\n",
    "    data = torch.LongTensor(data)\n",
    "    data = data.transpose(0, 1).contiguous().cuda()\n",
    "    outputs = model(data)\n",
    "    outputs = outputs.view(outputs.shape[0]*outputs.shape[1], outputs.shape[2])\n",
    "    outputs = outputs.data.cpu().numpy()\n",
    "    outputs = np.argmax(outputs, axis=1)\n",
    "    ner = \"\"\n",
    "    for i, j in enumerate(outputs):\n",
    "        ner =  ner + \" \" + words[i]+\"(\"+idx2tag[j].upper()+\")\"\n",
    "    print(ner.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carrie(PER) Mathison(O) a(O) CIA(O) operations(O) officer(O) conducts(O) an(O) unauthorized(O) operation(O) in(O) Iraq(GPE) and(O) is(O) reassigned(O) to(O) the(O) CIAs(O) Counterterrorism(O) Center(O) in(O) Langley(O) Virginia(GPE) Nicholas(O) Brody(PER) a(O) US(GPE) Marine(O) Sergeant(O) who(O) had(O) been(O) reported(O) as(O) missing(O) in(O) action(O) since(O) 2003(O) is(O) rescued(O) from(O) a(O) compound(O) belonging(O) to(O) terrorist(O) Abu(O) Nazir(O) Brody(PER) is(O) heralded(O) as(O) a(O) war(O) hero(O) but(O) Carrie(PER) comes(O) to(O) suspect(O) that(O) he(O) is(O) planning(O) a(O) terrorist(O) attack(O) against(O) the(O) United(GPE) States(GPE)\n"
     ]
    }
   ],
   "source": [
    "input_sentence = \"Carrie Mathison, a CIA operations officer, conducts an unauthorized operation in Iraq and is reassigned to the CIA's Counterterrorism Center in Langley, Virginia. Nicholas Brody, a U.S. Marine Sergeant who had been reported as missing in action since 2003, is rescued from a compound belonging to terrorist Abu Nazir. Brody is heralded as a war hero, but Carrie comes to suspect that he is planning a terrorist attack against the United States.\"\n",
    "predict(model, input_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
